{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"qFDGQB_5hDGg","executionInfo":{"status":"ok","timestamp":1680963509616,"user_tz":-60,"elapsed":8997,"user":{"displayName":"Karthik Talluri","userId":"10234119401099463436"}}},"outputs":[],"source":["#import  the libraries\n","import torch\n","import time\n","import torchvision\n","import torchvision.transforms as transforms\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, ConcatDataset\n","import torch.optim.lr_scheduler as lr_scheduler\n","import sklearn\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import KFold"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":883},"executionInfo":{"elapsed":45983,"status":"ok","timestamp":1680963555595,"user":{"displayName":"Karthik Talluri","userId":"10234119401099463436"},"user_tz":-60},"id":"iVCAa0z9kDc2","outputId":"9915349e-1875-4b6e-e1ec-3d444fd63a6b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.itl.nist.gov/iaui/vip/cs_links/EMNIST/gzip.zip to ./data/EMNIST/EMNIST/raw/gzip.zip\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 561753746/561753746 [00:04<00:00, 130693995.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/EMNIST/EMNIST/raw/gzip.zip to ./data/EMNIST/EMNIST/raw\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 1000x1000 with 36 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["train_set = torchvision.datasets.EMNIST(root = './data/EMNIST', download = True, split = 'balanced',\n","                                              train = True, transform = transforms.Compose([transforms.ToTensor(),]))\n","\n","test_set = torchvision.datasets.EMNIST(root = './data/EMNIST', download=True, split = 'balanced',\n","                                             train=False, transform = transforms.Compose([transforms.ToTensor()]))\n","\n","dataset = ConcatDataset([train_set, test_set])\n","# Visulize some figures\n","figure = plt.figure(figsize=(10, 10))\n","cols, rows = 6, 6\n","mapper = {}\n","path = '/content/drive/MyDrive/University_of_liverpool/AppliedAI/Assignment/emnist-balanced-mapping.txt'\n","with open(path) as f:\n","    for line in f:\n","       (key, val) = line.split()\n","       mapper[int(key)] = int(val)\n","for i in range(1, cols * rows + 1):\n","    sample_idx = torch.randint(len(train_set), size=(1,)).item()\n","    img, label = train_set[sample_idx]\n","    figure.add_subplot(rows, cols, i)\n","    # plt.title(\"Label \"+ str(label))\n","    plt.title(\"Ground Truth:{}\".format(chr(mapper[label])))\n","    plt.axis(\"off\")\n","    plt.imshow(img.squeeze(), cmap=\"gray\")\n","    \n","# plt.show()\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1680963555596,"user":{"displayName":"Karthik Talluri","userId":"10234119401099463436"},"user_tz":-60},"id":"rEqKQDQhTYG6","outputId":"6ffd2361-30de-4c9b-c380-ad0708bd27c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training data size: 112800\n","Training data size: 18800\n"]}],"source":["# DataLoader with the batch_size\n","print(\"Training data size: {}\".format(len(train_set)))\n","train_size=len(train_set)\n","test_size=len(test_set)\n","print(\"Training data size: {}\".format(len(test_set)))\n","\n","train_loader = torch.utils.data.DataLoader(train_set,batch_size=20)\n","\n","test_loader = torch.utils.data.DataLoader(test_set,batch_size=10000)"]},{"cell_type":"markdown","metadata":{"id":"CiGyxc_pTDu0"},"source":["# MLP"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1680963555596,"user":{"displayName":"Karthik Talluri","userId":"10234119401099463436"},"user_tz":-60},"id":"FquXze14Qc6G","outputId":"71305551-4c5d-4971-cd2d-88c6f8731823"},"outputs":[{"output_type":"stream","name":"stdout","text":["MLP(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): ReLU()\n","    (4): Linear(in_features=512, out_features=512, bias=True)\n","    (5): ReLU()\n","    (6): Linear(in_features=512, out_features=47, bias=True)\n","  )\n",")\n"]}],"source":["epochs = 15\n","n_hidden = 3\n","# Baseline Model\n","class MLP(nn.Module):\n","    def __init__(self):\n","        super(MLP, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 47),\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","\n","# define the model\n","model = MLP()\n","\n","print(model)\n","\n","# epochs = 15\n","# n_hidden = 3\n","# # Baseline Model\n","# class MLP(nn.Module):\n","#     def __init__(self, n_hidden = 3, scheduler = None, activation = None, optimizers = None, batch = False, L1 = False, L2 = False, Dropout = False):\n","#         super(MLP, self).__init__()\n","#         self.flatten = nn.Flatten()\n","#         layers = []\n","#         layers.append(nn.Linear(28*28, 512))\n","#         if Dropout:\n","#           layers.append(nn.Dropout(0.2))\n","#         for i in range(n_hidden):\n","#           if activation == 'elu':\n","#               layers.append(nn.ELU(0.1))\n","#           elif activation == 'leaky':\n","#             layers.append(nn.LeakyReLU(0.1))\n","#           elif activation == 'selu':\n","#             layers.append(nn.SELU(0.1))\n","#             layers.append(nn.Linear(512, 512))\n","#           if batch:\n","#             layers.append(nn.BatchNorm1d(512))\n","#           if L1:\n","#                 layers.append(nn.L1Loss())\n","#           if L2:\n","#               layers.append(nn.MSELoss())\n","#         layers.append(nn.Linear(512, 47))\n","#         self.linear_relu_stack = nn.Sequential(*layers)\n","\n","#     def forward(self, x):\n","#         x = self.flatten(x)\n","#         logits = self.linear_relu_stack(x)\n","#         return logits\n","#     def get_optimizer(self, lr):\n","#         optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n","#         if self.scheduler_type == 'step':\n","#             scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n","#         elif self.scheduler_type == 'exponential':\n","#             scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n","#         else:\n","#             scheduler = None\n","#         return optimizer, scheduler\n","\n","# # define the model\n","# model = MLP()\n","\n","# print(model)"]},{"cell_type":"code","source":["!pip install skorch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ZecN3OTS6RA","executionInfo":{"status":"ok","timestamp":1680951720312,"user_tz":-60,"elapsed":4157,"user":{"displayName":"Karthik Talluri","userId":"10234119401099463436"}},"outputId":"ae4bb559-17d3-4901-ec0d-0beb2ad7d7f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: skorch in /usr/local/lib/python3.9/dist-packages (0.12.1)\n","Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.9/dist-packages (from skorch) (0.8.10)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.9/dist-packages (from skorch) (1.22.4)\n","Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.9/dist-packages (from skorch) (1.2.2)\n","Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.9/dist-packages (from skorch) (4.65.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from skorch) (1.10.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.22.0->skorch) (3.1.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.22.0->skorch) (1.1.1)\n"]}]},{"cell_type":"code","source":["# import torch\n","# import torch.nn as nn\n","# from sklearn.model_selection import GridSearchCV\n","# from skorch import NeuralNetClassifier\n","# # Define MLP class\n","# class MLP(nn.Module):\n","#     def __init__(self, n_hidden, scheduler, activation, optimizers, batch=False, L1=False, L2=False):\n","#         super(MLP, self).__init__()\n","#         self.flatten = nn.Flatten()\n","#         layers = []\n","#         layers.append(nn.Linear(28*28, 512))\n","#         for i in range(n_hidden):\n","#             if activation == 'elu':\n","#                 layers.append(nn.ELU(0.1))\n","#             elif activation == 'leaky':\n","#                 layers.append(nn.LeakyReLU(0.1))\n","#             elif activation == 'selu':\n","#                 layers.append(nn.SELU(0.1))\n","#             layers.append(nn.Linear(512, 512))\n","#             if batch:\n","#                 layers.append(nn.BatchNorm1d(512))\n","#             # if Dropout:\n","#             #     layers.append(nn.Dropout(0.2))\n","#         layers.append(nn.ReLU())\n","#         layers.append(nn.Linear(512, 47))\n","#         self.linear_relu_stack = nn.Sequential(*layers)\n","#         self.L1 = L1\n","#         self.L2 = L2\n","\n","#     def forward(self, x):\n","#         x = self.flatten(x)\n","#         logits = self.linear_relu_stack(x)\n","#         return logits\n","\n","#     def l1_regularization(self, factor):\n","#         l1 = torch.tensor(0, dtype=torch.float32)\n","#         for p in self.parameters():\n","#             l1 += torch.norm(p, 1)\n","#         return factor * l1\n","\n","#     def l2_regularization(self, factor):\n","#         l2 = torch.tensor(0, dtype=torch.float32)\n","#         for p in self.parameters():\n","#             l2 += torch.norm(p, 2)\n","#         return factor * l2\n","\n","# def train_model(model, optimizer, criterion, train_loader, device):\n","#     model.train()\n","#     running_loss = 0.0\n","#     for batch_idx, (data, target) in enumerate(train_loader):\n","#         data, target = data.to(device), target.to(device)\n","#         optimizer.zero_grad()\n","#         output = model(data)\n","#         loss = criterion(output, target)\n","#         loss.backward()\n","#         optimizer.step()\n","#         running_loss += loss.item()\n","#     return running_loss / len(train_loader)\n","\n","# # Define hyperparameters for GridSearchCV\n","# params = {\n","#     'n_hidden': [2, 3, 4],\n","#     'batch': [True, False],\n","#     'L1': [True, False],\n","#     'L2': [True, False],\n","#     # 'Dropout': [True, False],\n","#     'scheduler': ['step', 'exp'],\n","#     'activation': ['elu', 'leaky', 'selu'],\n","#     'optimizers': [torch.optim.SGD, torch.optim.Adam, torch.optim.Adagrad]\n","# }\n","\n","# # Define dataset and dataloader\n","# # ...\n","\n","# # Define device\n","# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","# # Create MLP instance\n","# model = MLP(n_hidden=3, scheduler=None, activation='relu', optimizers=torch.optim.SGD)\n","\n","# # Define criterion and optimizer\n","# criterion = nn.CrossEntropyLoss()\n","# optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n","# net = NeuralNetClassifier(\n","#     module = MLP,\n","#     criterion=criterion,\n","#     optimizer=optimizer,\n","#     device=device,\n","#     iterator_train__shuffle=True,\n","# )\n","\n","# # Define GridSearchCV instance\n","# clf = GridSearchCV(net, params, scoring='accuracy', n_jobs=-1, cv=2)\n","# train_data = next(iter(train_loader))\n","# X_train, y_train = train_data[0], train_data[1]\n","# # Fit the data\n","# clf.fit(X_train, y_train, train_loader=train_loader)"],"metadata":{"id":"DxLKjN0LVR9u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#  you can set epoch size\n","def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","# define learning rate\n","learning_rate = 0.01\n","# set the epoch\n","epochs = 15\n","\n","\n","# loop over the dataset multiple times\n","losses = []\n","accuracies = []\n","results = {}\n","# for i in range(epochs):\n","#   correct = 0\n","#   for j,(images,targets) in enumerate(train_loader):\n","    \n","#     #making predictions\n","#     y_pred = model(images)\n","  \n","#     #calculating loss\n","#     loss = criterion(y_pred,targets.reshape(-1))\n","#     #backprop\n","#     optimizer.zero_grad()\n","#     loss.backward()\n","#     optimizer.step()\n","#     correct+= (y_pred.argmax(axis = 1) == targets).float().sum()\n","#   if i>10:\n","#     optimizer.lr = 0.0005\n","#   accuracy = 100* correct/len(train_set)\n","#   print(loss)\n","#   print(accuracy)\n","#   losses.append(loss)\n","#   accuracies.append(accuracy)\n","\n","# print('Complete Training')\n","k_folds = 3\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(train_set)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Sample elements randomly from a given list of ids, no replacement.\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    # Define data loaders for training and testing data in this fold\n","    trainloader = torch.utils.data.DataLoader(\n","                      train_set, \n","                      batch_size=20, sampler=train_subsampler)\n","    testloader = torch.utils.data.DataLoader(\n","                      train_set,\n","                      batch_size=1000, sampler=test_subsampler)\n","    model = MLP()\n","    model.apply(reset_weights)\n","        # define your optimizer with SGD and learning rate\n","    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n","    # define the loss function\n","    criterion = nn.CrossEntropyLoss()\n","    for i in range(epochs):\n","        correct = 0\n","        training_start_time = time.time()\n","        for j,(images,targets) in enumerate(trainloader):\n","            #making predictions\n","            y_pred = model(images)\n","            #calculating loss\n","            loss = criterion(y_pred,targets.reshape(-1))\n","            #backprop\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            correct += (y_pred.argmax(axis = 1) == targets).float().sum()\n","        accuracy = 100 * correct / len(train_set)\n","        # if i>10:\n","        #   optimizer.lr = 0.0005\n","        print(loss)\n","        print(accuracy)\n","        losses.append(loss)\n","        accuracies.append(accuracy)\n","\n","    print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n","    print(f'accuracy during training is {accuracy.item()}')\n","    print(f\"loss after training is {loss.item()}\")"],"metadata":{"id":"-NxCix3jNZX0","executionInfo":{"status":"error","timestamp":1680963409180,"user_tz":-60,"elapsed":47670,"user":{"displayName":"Karthik Talluri","userId":"10234119401099463436"}},"colab":{"base_uri":"https://localhost:8080/","height":532},"outputId":"08c53015-a949-4a46-b7f5-4c8d2d158abb"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["FOLD 0\n","--------------------------------\n","Reset trainable parameters of layer = Linear(in_features=784, out_features=512, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=512, out_features=512, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=512, out_features=512, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=512, out_features=47, bias=True)\n","tensor(2.0962, grad_fn=<NllLossBackward0>)\n","tensor(16.8422)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-52-67c8f0a3b3f3>\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mtraining_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0;31m#making predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# put it from HWC to CHW format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["k_folds = 3\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(train_set)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Define data loaders for training and testing data in this fold\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    trainloader = torch.utils.data.DataLoader(\n","                      train_set, \n","                      batch_size=20, sampler=train_subsampler)\n","    testloader = torch.utils.data.DataLoader(\n","                      train_set,\n","                      batch_size=1000, sampler=test_subsampler)\n","\n","    model = MLP()\n","    model.apply(reset_weights)\n","    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n","    criterion = nn.CrossEntropyLoss()\n","    losses = []\n","    accuracies = []\n","\n","    for i in range(epochs):\n","        correct = 0\n","        training_start_time = time.time()\n","        for j, (images, targets) in enumerate(trainloader):\n","            #making predictions\n","            y_pred = model(images)\n","            #calculating loss\n","            loss = criterion(y_pred, targets)\n","            #backprop\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","            correct += (y_pred.argmax(axis = 1) == targets).float().sum()\n","            if j == 0 and i > 10:\n","                optimizer.lr = 0.0005\n","        accuracy = 100 * correct / len(train_ids)\n","        print(loss)\n","        print(accuracy)\n","        losses.append(loss.item())\n","        accuracies.append(accuracy.item())\n","\n","    print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n","    print(f'accuracy during training is {accuracies[-1]}')\n","    print(f\"loss after training is {losses[-1]}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":603},"id":"ukPHaZq8KkHd","executionInfo":{"status":"error","timestamp":1680962473713,"user_tz":-60,"elapsed":99265,"user":{"displayName":"Karthik Talluri","userId":"10234119401099463436"}},"outputId":"30eadc27-117f-43bc-e8d8-b3c5c89bf268"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["FOLD 0\n","--------------------------------\n","Reset trainable parameters of layer = Linear(in_features=784, out_features=512, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=512, out_features=512, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=512, out_features=512, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=512, out_features=47, bias=True)\n","tensor(1.8606, grad_fn=<NllLossBackward0>)\n","tensor(24.7739)\n","tensor(0.9617, grad_fn=<NllLossBackward0>)\n","tensor(60.2979)\n","tensor(0.8589, grad_fn=<NllLossBackward0>)\n","tensor(69.4987)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-49-a174447374f7>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtraining_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0;31m#making predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_float_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":897331,"status":"error","timestamp":1680964452904,"user":{"displayName":"Karthik Talluri","userId":"10234119401099463436"},"user_tz":-60},"id":"81vaZoCzWBhQ","outputId":"aa93235f-4d3e-43f2-d4c7-42a2175e5bdc"},"outputs":[{"output_type":"stream","name":"stdout","text":["FOLD 0\n","--------------------------------\n","Reset trainable parameters of layer = Linear(in_features=784, out_features=512, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=512, out_features=512, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=512, out_features=512, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=512, out_features=47, bias=True)\n","tensor(2.4041, grad_fn=<NllLossBackward0>)\n","tensor(16.5541)\n","tensor(1.6590, grad_fn=<NllLossBackward0>)\n","tensor(55.5612)\n","tensor(1.5123, grad_fn=<NllLossBackward0>)\n","tensor(65.8892)\n","tensor(1.3271, grad_fn=<NllLossBackward0>)\n","tensor(71.2278)\n","tensor(1.1667, grad_fn=<NllLossBackward0>)\n","tensor(74.8032)\n","tensor(1.0369, grad_fn=<NllLossBackward0>)\n","tensor(77.1871)\n","tensor(0.9497, grad_fn=<NllLossBackward0>)\n","tensor(78.9672)\n","tensor(0.8778, grad_fn=<NllLossBackward0>)\n","tensor(80.2934)\n","tensor(0.8124, grad_fn=<NllLossBackward0>)\n","tensor(81.3103)\n","tensor(0.7601, grad_fn=<NllLossBackward0>)\n","tensor(82.1924)\n","tensor(0.7044, grad_fn=<NllLossBackward0>)\n","tensor(82.9246)\n","tensor(0.6522, grad_fn=<NllLossBackward0>)\n","tensor(83.5993)\n","tensor(0.6120, grad_fn=<NllLossBackward0>)\n","tensor(84.1144)\n","tensor(0.5740, grad_fn=<NllLossBackward0>)\n","tensor(84.6135)\n","tensor(0.5381, grad_fn=<NllLossBackward0>)\n","tensor(85.0080)\n","Training finished, took 39.50s\n","accuracy during training is 85.00798034667969\n","loss after training is 0.5380533337593079\n","Accuracy for fold 0: 85 %\n","--------------------------------\n","FOLD 1\n","--------------------------------\n","Reset trainable parameters of layer = Linear(in_features=784, out_features=512, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=512, out_features=512, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=512, out_features=512, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=512, out_features=47, bias=True)\n","tensor(2.3349, grad_fn=<NllLossBackward0>)\n","tensor(17.7048)\n","tensor(1.5831, grad_fn=<NllLossBackward0>)\n","tensor(56.1330)\n","tensor(1.4337, grad_fn=<NllLossBackward0>)\n","tensor(66.3138)\n","tensor(1.2606, grad_fn=<NllLossBackward0>)\n","tensor(71.5541)\n","tensor(1.1284, grad_fn=<NllLossBackward0>)\n","tensor(75.0638)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-c4c52fb7c770>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m       \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m       \u001b[0mtraining_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;31m#making predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2854\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2856\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   2789\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_MAPMODES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2791\u001b[0;31m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2792\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2793\u001b[0m             \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadonly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mnew\u001b[0;34m(mode, size, color)\u001b[0m\n\u001b[1;32m   2703\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImagePalette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImagePalette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2704\u001b[0m         \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpalette\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2705\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#  you can set epoch size\n","def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","k_folds = 3\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","# define learning rate\n","learning_rate = 0.005\n","# set the epoch\n","epochs = 15\n","\n","\n","# loop over the dataset multiple times\n","losses = []\n","accuracies = []\n","results = {}\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(train_set)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Sample elements randomly from a given list of ids, no replacement.\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    # Define data loaders for training and testing data in this fold\n","    trainloader = torch.utils.data.DataLoader(\n","                      train_set, \n","                      batch_size=20, sampler=train_subsampler)\n","    testloader = torch.utils.data.DataLoader(\n","                      train_set,\n","                      batch_size=1000, sampler=test_subsampler)\n","    model = MLP()\n","    model.apply(reset_weights)\n","        # define your optimizer with SGD and learning rate\n","    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n","    # define the loss function\n","    criterion = nn.CrossEntropyLoss()\n","    for i in range(epochs):\n","      correct = 0\n","      training_start_time = time.time()\n","      for j,(images,targets) in enumerate(train_loader):\n","        #making predictions\n","        y_pred = model(images)\n","        #calculating loss\n","        loss = criterion(y_pred,targets.reshape(-1))\n","        #backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        correct += (y_pred.argmax(axis = 1) == targets).float().sum()\n","      accuracy = 100 * correct / len(train_set)\n","      if i>10:\n","        optimizer.lr = 0.0005\n","      print(loss)\n","      print(accuracy)\n","      losses.append(loss)\n","      accuracies.append(accuracy)\n","\n","    print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n","    print(f'accuracy during training is {accuracy.item()}')\n","    print(f\"loss after training is {loss.item()}\")\n","     # Evaluationfor this fold\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","\n","      # Iterate over the test data and generate predictions\n","      for i, data in enumerate(testloader, 0):\n","\n","        # Get inputs\n","        inputs, targets = data\n","\n","        # Generate outputs\n","        outputs = model(inputs)\n","\n","        # Set total and correct\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","      # Print accuracy\n","      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n","      print('--------------------------------')\n","      results[fold] = 100.0 * (correct / total)\n","    \n","# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","for key, value in results.items():\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","print(f'Average: {sum/len(results.items())} %')"]},{"cell_type":"markdown","metadata":{"id":"N1dii7MY8c6Z"},"source":["## Loss function and Accuracy Graph\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-aR8VYchBmKQ"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# losses is the list of losses generated during training\n","plt.plot([loss.detach().numpy() for loss in losses])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","plt.show()\n","# losses is the list of losses generated during training\n","plt.plot([acc.detach().numpy() for acc in accuracies])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Accuracy')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"jqO-QD4z6Yhi"},"source":["## Adaptive Learning rate"]},{"cell_type":"markdown","metadata":{"id":"SQx0npI9An_-"},"source":["### Step based scheduler"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":532},"executionInfo":{"elapsed":78520,"status":"error","timestamp":1680964539421,"user":{"displayName":"Karthik Talluri","userId":"10234119401099463436"},"user_tz":-60},"id":"LI22e4kx6OY4","outputId":"8ec9b7ca-f685-4a44-d13b-f9c3f17065f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["FOLD 0\n","--------------------------------\n","Reset trainable parameters of layer = Linear(in_features=784, out_features=512, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=512, out_features=512, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=512, out_features=512, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=512, out_features=47, bias=True)\n","tensor(0.9662, grad_fn=<NllLossBackward0>)\n","tensor(62.7606)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-3487345aa7c5>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m#making predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;31m#calculating loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-1fc3fb4c0859>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_relu_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","lrs = []\n","\n","\n","\n","# loop over the dataset multiple times\n","losses = []\n","accuracies = []\n","#  you can set epoch size\n","def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","k_folds = 3\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","results = {}\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(train_set)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Sample elements randomly from a given list of ids, no replacement.\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    # Define data loaders for training and testing data in this fold\n","    trainloader = torch.utils.data.DataLoader(\n","                      train_set, \n","                      batch_size=10, sampler=train_subsampler)\n","    testloader = torch.utils.data.DataLoader(\n","                      train_set,\n","                      batch_size=10, sampler=test_subsampler)\n","    model = MLP()\n","    model.apply(reset_weights)\n","    #  you can set epoch size\n","    epochs = 15\n","    # define learning rate\n","    learning_rate = 0.05\n","    # define your optimizer with SGD and learning rate\n","    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n","    # define the loss function\n","    criterion = nn.CrossEntropyLoss()\n","    # Step based scheduling method\n","    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n","    for i in range(epochs):\n","      correct = 0\n","      for j,(images,targets) in enumerate(train_loader):\n","        \n","        #making predictions\n","        y_pred = model(images)\n","        #calculating loss\n","        loss = criterion(y_pred,targets.reshape(-1))\n","        #backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        correct += (y_pred.argmax(axis = 1) == targets).float().sum()\n","      scheduler.step()\n","      lrs.append(optimizer.param_groups[0][\"lr\"])\n","      accuracy = 100 * correct / len(train_set)\n","      # if i>10:\n","      #   optimizer.lr = 0.0005\n","      print(loss)\n","      print(accuracy)\n","      losses.append(loss)\n","      accuracies.append(accuracy)\n","\n","    print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n","    print(f'accuracy during training is {accuracy.item()}')\n","    print(f\"loss after training is {loss.item()}\")\n","     # Evaluationfor this fold\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","\n","      # Iterate over the test data and generate predictions\n","      for i, data in enumerate(testloader, 0):\n","\n","        # Get inputs\n","        inputs, targets = data\n","\n","        # Generate outputs\n","        outputs = model(inputs)\n","\n","        # Set total and correct\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","      # Print accuracy\n","      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n","      print('--------------------------------')\n","      results[fold] = 100.0 * (correct / total)\n","    \n","# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","for key, value in results.items():\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","print(f'Average: {sum/len(results.items())} %')\n","# losses is the list of losses generated during training\n","plt.plot([loss.detach().numpy() for loss in losses])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","plt.show()\n","# losses is the list of losses generated during training\n","plt.plot([acc.detach().numpy() for acc in accuracies])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Accuracy')\n","plt.show()\n","\n","plt.plot([lr for lr in lrs])\n","plt.show()\n","\n","print(lrs)"]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":532},"id":"eyQX7TOs8Qqm","executionInfo":{"status":"error","timestamp":1680959052167,"user_tz":-60,"elapsed":185978,"user":{"displayName":"Karthik Talluri","userId":"10234119401099463436"}},"outputId":"bbf98db2-3a35-4825-d609-cfd0f92d4303"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(3.8508, grad_fn=<NllLossBackward0>)\n","tensor(2.0576)\n","tensor(3.8508, grad_fn=<NllLossBackward0>)\n","tensor(2.0576)\n","tensor(3.8508, grad_fn=<NllLossBackward0>)\n","tensor(2.0576)\n","tensor(3.8508, grad_fn=<NllLossBackward0>)\n","tensor(2.0576)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-64b12ecd14de>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m       \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m#making predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"pic should be PIL Image or ndarray. Got {type(pic)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_is_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_numpy_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"pic should be 2/3 dimensional. Got {pic.ndim} dimensions.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36m_is_numpy\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munused\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_is_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"kRkjPB-oAyzL"},"source":["### Exponenential scheduler"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":84541,"status":"error","timestamp":1680964637149,"user":{"displayName":"Karthik Talluri","userId":"10234119401099463436"},"user_tz":-60},"id":"hWzbj5T6A12c","colab":{"base_uri":"https://localhost:8080/","height":568},"outputId":"23ef8ed0-98ae-40ac-d097-d8df2cb3a0bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["FOLD 0\n","--------------------------------\n","Reset trainable parameters of layer = Linear(in_features=784, out_features=512, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=512, out_features=512, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=512, out_features=512, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=512, out_features=47, bias=True)\n","tensor(0.9980, grad_fn=<NllLossBackward0>)\n","tensor(62.4326)\n","tensor(0.6566, grad_fn=<NllLossBackward0>)\n","tensor(82.3298)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-0dd12c4880c0>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m       \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m#making predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2854\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2856\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   2788\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2789\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2790\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_MAPMODES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2791\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2792\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","lrs = []\n","import numpy as np\n","import matplotlib.pyplot as plt\n","#  you can set epoch size\n","\n","# define learning rate\n","learning_rate = 0.05\n","# define your optimizer with SGD and learning rate\n","optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n","# define the loss function\n","criterion = nn.CrossEntropyLoss()\n","# Step based scheduling method\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n","lrs = []\n","# loop over the dataset multiple times\n","losses = []\n","accuracies = []\n","#  you can set epoch size\n","def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","k_folds = 5\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","results = {}\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(train_set)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Sample elements randomly from a given list of ids, no replacement.\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    # Define data loaders for training and testing data in this fold\n","    trainloader = torch.utils.data.DataLoader(\n","                      train_set, \n","                      batch_size=10, sampler=train_subsampler)\n","    testloader = torch.utils.data.DataLoader(\n","                      train_set,\n","                      batch_size=10, sampler=test_subsampler)\n","    model = MLP()\n","    model.apply(reset_weights)\n","    #  you can set epoch size\n","    epochs = 15\n","    # define learning rate\n","    learning_rate = 0.05\n","    # define your optimizer with SGD and learning rate\n","    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n","    # define the loss function\n","    criterion = nn.CrossEntropyLoss()\n","    # set the epoch\n","    # Step based scheduling method\n","    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)\n","    for i in range(epochs):\n","      correct = 0\n","      for j,(images,targets) in enumerate(train_loader):\n","        \n","        #making predictions\n","        y_pred = model(images)\n","        #calculating loss\n","        loss = criterion(y_pred,targets.reshape(-1))\n","        #backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        lrs.append(optimizer.param_groups[0][\"lr\"])\n","        correct += (y_pred.argmax(axis = 1) == targets).float().sum()\n","      scheduler.step()\n","      accuracy = 100 * correct / len(train_set)\n","      # if i>10:\n","      #   optimizer.lr = 0.0005\n","      print(loss)\n","      print(accuracy)\n","      losses.append(loss)\n","      accuracies.append(accuracy)\n","\n","    print('Complete Training')\n","\n","    print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n","    print(f'accuracy during training is {accuracy.item()}')\n","    print(f\"loss after training is {loss.item()}\")\n","     # Evaluationfor this fold\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","\n","      # Iterate over the test data and generate predictions\n","      for i, data in enumerate(testloader, 0):\n","\n","        # Get inputs\n","        inputs, targets = data\n","\n","        # Generate outputs\n","        outputs = model(inputs)\n","\n","        # Set total and correct\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","      # Print accuracy\n","      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n","      print('--------------------------------')\n","      results[fold] = 100.0 * (correct / total)\n","    \n","# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","for key, value in results.items():\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","print(f'Average: {sum/len(results.items())} %')\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# losses is the list of losses generated during training\n","plt.plot([loss.detach().numpy() for loss in losses])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","plt.show()\n","# losses is the list of losses generated during training\n","plt.plot([acc.detach().numpy() for acc in accuracies])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Accuracy')\n","plt.show()\n","\n","plt.plot([lr for lr in lrs])\n","plt.show()\n","\n","print(lrs)"]},{"cell_type":"markdown","metadata":{"id":"oQMB2JYB6hEC"},"source":["## Activation function"]},{"cell_type":"markdown","metadata":{"id":"ITV0fLasCelq"},"source":["### Leaky Relu"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":138461,"status":"error","timestamp":1680964816442,"user":{"displayName":"Karthik Talluri","userId":"10234119401099463436"},"user_tz":-60},"id":"H2QQVvpdBi6j","colab":{"base_uri":"https://localhost:8080/","height":836},"outputId":"a1b19fca-36f0-411f-b873-f0a7b0ef3c4a"},"outputs":[{"output_type":"stream","name":"stdout","text":["MLP(\n","  (flatten): Flatten(start_dim=1, end_dim=-1)\n","  (linear_relu_stack): Sequential(\n","    (0): Linear(in_features=784, out_features=512, bias=True)\n","    (1): LeakyReLU(negative_slope=0.1)\n","    (2): Linear(in_features=512, out_features=512, bias=True)\n","    (3): LeakyReLU(negative_slope=0.1)\n","    (4): Linear(in_features=512, out_features=512, bias=True)\n","    (5): LeakyReLU(negative_slope=0.1)\n","    (6): Linear(in_features=512, out_features=512, bias=True)\n","    (7): LeakyReLU(negative_slope=0.1)\n","    (8): Linear(in_features=512, out_features=47, bias=True)\n","  )\n",")\n","FOLD 0\n","--------------------------------\n","Reset trainable parameters of layer = Linear(in_features=784, out_features=512, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=512, out_features=512, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=512, out_features=512, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=512, out_features=512, bias=True)\n","Reset trainable parameters of layer = Linear(in_features=512, out_features=47, bias=True)\n","tensor(3.6438, grad_fn=<NllLossBackward0>)\n","tensor(8.3963)\n","tensor(1.8992, grad_fn=<NllLossBackward0>)\n","tensor(33.4619)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-c192d281384b>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m#making predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;31m#calculating loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-c192d281384b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_relu_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["class MLP(nn.Module):\n","    def __init__(self):\n","        super(MLP, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.LeakyReLU(0.1),\n","            nn.Linear(512, 512),\n","            nn.LeakyReLU(0.1),\n","            nn.Linear(512, 512),\n","            nn.LeakyReLU(0.1),\n","            nn.Linear(512, 512),\n","            nn.LeakyReLU(0.1),\n","            nn.Linear(512, 47),\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","\n","# define the model\n","model_leaky = MLP()\n","print(model_leaky)\n","#  you can set epoch size\n","def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","k_folds = 3\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","# define learning rate\n","epochs = 15\n","\n","\n","# loop over the dataset multiple times\n","losses = []\n","accuracies = []\n","results = {}\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(train_set)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Sample elements randomly from a given list of ids, no replacement.\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    # Define data loaders for training and testing data in this fold\n","    trainloader = torch.utils.data.DataLoader(\n","                      train_set, \n","                      batch_size=10, sampler=train_subsampler)\n","    testloader = torch.utils.data.DataLoader(\n","                      train_set,\n","                      batch_size=10, sampler=test_subsampler)\n","    model = MLP()\n","    model.apply(reset_weights)\n","    learning_rate = 0.005\n","    # define your optimizer with SGD and learning rate\n","    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n","    # define the loss function\n","    criterion = nn.CrossEntropyLoss()\n","    # set the epoch\n","    for i in range(epochs):\n","      correct = 0\n","      training_start_time = time.time()\n","      for j,(images,targets) in enumerate(train_loader):\n","        #making predictions\n","        y_pred = model(images)\n","        #calculating loss\n","        loss = criterion(y_pred,targets.reshape(-1))\n","        #backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        correct += (y_pred.argmax(axis = 1) == targets).float().sum()\n","      accuracy = 100 * correct / len(train_set)\n","      if i>10:\n","        optimizer.lr = 0.0005\n","      print(loss)\n","      print(accuracy)\n","      losses.append(loss)\n","      accuracies.append(accuracy)\n","\n","    print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n","    print(f'accuracy during training is {accuracy.item()}')\n","    print(f\"loss after training is {loss.item()}\")\n","     # Evaluationfor this fold\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","\n","      # Iterate over the test data and generate predictions\n","      for i, data in enumerate(testloader, 0):\n","\n","        # Get inputs\n","        inputs, targets = data\n","\n","        # Generate outputs\n","        outputs = model(inputs)\n","\n","        # Set total and correct\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","      # Print accuracy\n","      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n","      print('--------------------------------')\n","      results[fold] = 100.0 * (correct / total)\n","    \n","# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","for key, value in results.items():\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","print(f'Average: {sum/len(results.items())} %')\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# losses is the list of losses generated during training\n","plt.plot([loss.detach().numpy() for loss in losses])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","plt.show()\n","# losses is the list of losses generated during training\n","plt.plot([acc.detach().numpy() for acc in accuracies])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Accuracy')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"jJTalhBNDZGu"},"source":["### ELU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kkv9wFXFDfFN"},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self):\n","        super(MLP, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.ELU(0.1),\n","            nn.Linear(512, 512),\n","            nn.ELU(0.1),\n","            nn.Linear(512, 512),\n","            nn.ELU(0.1),\n","            nn.Linear(512, 512),\n","            nn.ELU(0.1),\n","            nn.Linear(512, 47),\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","\n","# define the model\n","model_elu = MLP()\n","\n","print(model_elu)\n","#  you can set epoch size\n","def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","k_folds = 3\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","# set the epoch\n","epochs = 15\n","\n","\n","# loop over the dataset multiple times\n","losses = []\n","accuracies = []\n","results = {}\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(train_set)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Sample elements randomly from a given list of ids, no replacement.\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    # Define data loaders for training and testing data in this fold\n","    trainloader = torch.utils.data.DataLoader(\n","                      train_set, \n","                      batch_size=10, sampler=train_subsampler)\n","    testloader = torch.utils.data.DataLoader(\n","                      train_set,\n","                      batch_size=10, sampler=test_subsampler)\n","    model = MLP()\n","    model.apply(reset_weights)\n","    # define learning rate\n","    learning_rate = 0.005\n","    # define your optimizer with SGD and learning rate\n","    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n","    # define the loss function\n","    criterion = nn.CrossEntropyLoss()\n","    for i in range(epochs):\n","      correct = 0\n","      training_start_time = time.time()\n","      for j,(images,targets) in enumerate(train_loader):\n","        #making predictions\n","        y_pred = model(images)\n","        #calculating loss\n","        loss = criterion(y_pred,targets.reshape(-1))\n","        #backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        correct += (y_pred.argmax(axis = 1) == targets).float().sum()\n","      accuracy = 100 * correct / len(train_set)\n","      if i>10:\n","        optimizer.lr = 0.0005\n","      print(loss)\n","      print(accuracy)\n","      losses.append(loss)\n","      accuracies.append(accuracy)\n","\n","    print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n","    print(f'accuracy during training is {accuracy.item()}')\n","    print(f\"loss after training is {loss.item()}\")\n","     # Evaluationfor this fold\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","\n","      # Iterate over the test data and generate predictions\n","      for i, data in enumerate(testloader, 0):\n","\n","        # Get inputs\n","        inputs, targets = data\n","\n","        # Generate outputs\n","        outputs = model(inputs)\n","\n","        # Set total and correct\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","      # Print accuracy\n","      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n","      print('--------------------------------')\n","      results[fold] = 100.0 * (correct / total)\n","    \n","# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","for key, value in results.items():\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","print(f'Average: {sum/len(results.items())} %')\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# losses is the list of losses generated during training\n","plt.plot([loss.detach().numpy() for loss in losses])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","plt.show()\n","# losses is the list of losses generated during training\n","plt.plot([acc.detach().numpy() for acc in accuracies])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Accuracy')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Y63iRBB-EQD7"},"source":["### SELU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"clsHmmv_ESHq"},"outputs":[],"source":["class MLP(nn.Module):\n","    def __init__(self):\n","        super(MLP, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.SELU(0.1),\n","            nn.Linear(512, 512),\n","            nn.SELU(0.1),\n","            nn.Linear(512, 512),\n","            nn.SELU(0.1),\n","            nn.Linear(512, 512),\n","            nn.SELU(0.1),\n","            nn.Linear(512, 47),\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","\n","# define the model\n","model_selu = MLP()\n","\n","print(model_selu)\n","#  you can set epoch size\n","def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","k_folds = 3\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","# set the epoch\n","epochs = 15\n","\n","\n","# loop over the dataset multiple times\n","losses = []\n","accuracies = []\n","results = {}\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(train_set)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Sample elements randomly from a given list of ids, no replacement.\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    # Define data loaders for training and testing data in this fold\n","    trainloader = torch.utils.data.DataLoader(\n","                      train_set, \n","                      batch_size=10, sampler=train_subsampler)\n","    testloader = torch.utils.data.DataLoader(\n","                      train_set,\n","                      batch_size=10, sampler=test_subsampler)\n","    model = MLP()\n","    model.apply(reset_weights)\n","    # define learning rate\n","    learning_rate = 0.005\n","    # define your optimizer with SGD and learning rate\n","    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n","    # define the loss function\n","    criterion = nn.CrossEntropyLoss()\n","    for i in range(epochs):\n","      correct = 0\n","      training_start_time = time.time()\n","      for j,(images,targets) in enumerate(train_loader):\n","        #making predictions\n","        y_pred = model(images)\n","        #calculating loss\n","        loss = criterion(y_pred,targets.reshape(-1))\n","        #backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        correct += (y_pred.argmax(axis = 1) == targets).float().sum()\n","      accuracy = 100 * correct / len(train_set)\n","      if i>10:\n","        optimizer.lr = 0.0005\n","      print(loss)\n","      print(accuracy)\n","      losses.append(loss)\n","      accuracies.append(accuracy)\n","\n","    print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n","    print(f'accuracy during training is {accuracy.item()}')\n","    print(f\"loss after training is {loss.item()}\")\n","     # Evaluationfor this fold\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","\n","      # Iterate over the test data and generate predictions\n","      for i, data in enumerate(testloader, 0):\n","\n","        # Get inputs\n","        inputs, targets = data\n","\n","        # Generate outputs\n","        outputs = model(inputs)\n","\n","        # Set total and correct\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","      # Print accuracy\n","      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n","      print('--------------------------------')\n","      results[fold] = 100.0 * (correct / total)\n","    \n","# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","for key, value in results.items():\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","print(f'Average: {sum/len(results.items())} %')\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# losses is the list of losses generated during training\n","plt.plot([loss.detach().numpy() for loss in losses])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","plt.show()\n","# losses is the list of losses generated during training\n","plt.plot([acc.detach().numpy() for acc in accuracies])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Accuracy')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"KDKQBwma6kXk"},"source":["## Optimizers"]},{"cell_type":"markdown","metadata":{"id":"6nIo-AEDEeKQ"},"source":["### Adam"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WH5v8UfEEgA9"},"outputs":[],"source":["#  you can set epoch size\n","def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","k_folds = 3\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","# define learning rate\n","# set the epoch\n","epochs = 15\n","\n","\n","# loop over the dataset multiple times\n","losses = []\n","accuracies = []\n","results = {}\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(train_set)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Sample elements randomly from a given list of ids, no replacement.\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    # Define data loaders for training and testing data in this fold\n","    trainloader = torch.utils.data.DataLoader(\n","                      train_set, \n","                      batch_size=10, sampler=train_subsampler)\n","    testloader = torch.utils.data.DataLoader(\n","                      train_set,\n","                      batch_size=10, sampler=test_subsampler)\n","    model = MLP()\n","    model.apply(reset_weights)\n","    learning_rate = 0.005\n","    # define your optimizer with SGD and learning rate\n","    optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n","    # define the loss function\n","    criterion = nn.CrossEntropyLoss()\n","    for i in range(epochs):\n","      correct = 0\n","      training_start_time = time.time()\n","      for j,(images,targets) in enumerate(train_loader):\n","        #making predictions\n","        y_pred = model(images)\n","        #calculating loss\n","        loss = criterion(y_pred,targets.reshape(-1))\n","        #backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        correct += (y_pred.argmax(axis = 1) == targets).float().sum()\n","      accuracy = 100 * correct / len(train_set)\n","      if i>10:\n","        optimizer.lr = 0.0005\n","      print(loss)\n","      print(accuracy)\n","      losses.append(loss)\n","      accuracies.append(accuracy)\n","\n","    print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n","    print(f'accuracy during training is {accuracy.item()}')\n","    print(f\"loss after training is {loss.item()}\")\n","     # Evaluationfor this fold\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","\n","      # Iterate over the test data and generate predictions\n","      for i, data in enumerate(testloader, 0):\n","\n","        # Get inputs\n","        inputs, targets = data\n","\n","        # Generate outputs\n","        outputs = model(inputs)\n","\n","        # Set total and correct\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","      # Print accuracy\n","      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n","      print('--------------------------------')\n","      results[fold] = 100.0 * (correct / total)\n","    \n","# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","for key, value in results.items():\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","print(f'Average: {sum/len(results.items())} %')\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# losses is the list of losses generated during training\n","plt.plot([loss.detach().numpy() for loss in losses])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","plt.show()\n","# losses is the list of losses generated during training\n","plt.plot([acc.detach().numpy() for acc in accuracies])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Accuracy')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"2q3ixZpcFbjl"},"source":["### Adagrad"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gkR94fm-FdUI"},"outputs":[],"source":["#  you can set epoch size\n","\n","#  you can set epoch size\n","def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","k_folds = 3\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","# set the epoch\n","epochs = 15\n","\n","\n","# loop over the dataset multiple times\n","losses = []\n","accuracies = []\n","results = {}\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(train_set)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Sample elements randomly from a given list of ids, no replacement.\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    # Define data loaders for training and testing data in this fold\n","    trainloader = torch.utils.data.DataLoader(\n","                      train_set, \n","                      batch_size=10, sampler=train_subsampler)\n","    testloader = torch.utils.data.DataLoader(\n","                      train_set,\n","                      batch_size=10, sampler=test_subsampler)\n","    model = MLP()\n","    model.apply(reset_weights)\n","    # define learning rate\n","    learning_rate = 0.005\n","    # define your optimizer with SGD and learning rate\n","    optimizer = torch.optim.Adagrad(model.parameters(),lr=learning_rate)\n","    # define the loss function\n","    criterion = nn.CrossEntropyLoss()\n","    for i in range(epochs):\n","      correct = 0\n","      training_start_time = time.time()\n","      for j,(images,targets) in enumerate(train_loader):\n","        #making predictions\n","        y_pred = model(images)\n","        #calculating loss\n","        loss = criterion(y_pred,targets.reshape(-1))\n","        #backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        correct += (y_pred.argmax(axis = 1) == targets).float().sum()\n","      accuracy = 100 * correct / len(train_set)\n","      if i>10:\n","        optimizer.lr = 0.0005\n","      print(loss)\n","      print(accuracy)\n","      losses.append(loss)\n","      accuracies.append(accuracy)\n","\n","    print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n","    print(f'accuracy during training is {accuracy.item()}')\n","    print(f\"loss after training is {loss.item()}\")\n","     # Evaluationfor this fold\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","\n","      # Iterate over the test data and generate predictions\n","      for i, data in enumerate(testloader, 0):\n","\n","        # Get inputs\n","        inputs, targets = data\n","\n","        # Generate outputs\n","        outputs = model(inputs)\n","\n","        # Set total and correct\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","      # Print accuracy\n","      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n","      print('--------------------------------')\n","      results[fold] = 100.0 * (correct / total)\n","    \n","# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","for key, value in results.items():\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","print(f'Average: {sum/len(results.items())} %')\n","  import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# losses is the list of losses generated during training\n","plt.plot([loss.detach().numpy() for loss in losses])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","plt.show()\n","# losses is the list of losses generated during training\n","plt.plot([acc.detach().numpy() for acc in accuracies])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Accuracy')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"TGV2WUhW6nSs"},"source":["## Batch Normalization"]},{"cell_type":"markdown","metadata":{"id":"qVGN2KmNFu56"},"source":["### With Batch Normalization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rb10xE8JFyHo"},"outputs":[],"source":["# Baseline Model\n","class MLP(nn.Module):\n","    def __init__(self):\n","        super(MLP, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(28*28, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","            nn.Linear(512, 47),\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","\n","# define the model\n","model_batch = MLP()\n","\n","print(model_batch)     \n","\n","#  you can set epoch size\n","def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","k_folds = 3\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","# set the epoch\n","epochs = 15\n","\n","\n","# loop over the dataset multiple times\n","losses = []\n","accuracies = []\n","results = {}\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(train_set)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Sample elements randomly from a given list of ids, no replacement.\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    # Define data loaders for training and testing data in this fold\n","    trainloader = torch.utils.data.DataLoader(\n","                      train_set, \n","                      batch_size=10, sampler=train_subsampler)\n","    testloader = torch.utils.data.DataLoader(\n","                      train_set,\n","                      batch_size=10, sampler=test_subsampler)\n","    model = MLP()\n","    model.apply(reset_weights)\n","        # define learning rate\n","    learning_rate = 0.005\n","    # define your optimizer with SGD and learning rate\n","    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n","    # define the loss function\n","    criterion = nn.CrossEntropyLoss()\n","    for i in range(epochs):\n","      correct = 0\n","      training_start_time = time.time()\n","      for j,(images,targets) in enumerate(train_loader):\n","        #making predictions\n","        y_pred = model(images)\n","        #calculating loss\n","        loss = criterion(y_pred,targets.reshape(-1))\n","        #backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        correct += (y_pred.argmax(axis = 1) == targets).float().sum()\n","      accuracy = 100 * correct / len(train_set)\n","      if i>10:\n","        optimizer.lr = 0.0005\n","      print(loss)\n","      print(accuracy)\n","      losses.append(loss)\n","      accuracies.append(accuracy)\n","\n","    print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n","    print(f'accuracy during training is {accuracy.item()}')\n","    print(f\"loss after training is {loss.item()}\")\n","     # Evaluationfor this fold\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","\n","      # Iterate over the test data and generate predictions\n","      for i, data in enumerate(testloader, 0):\n","\n","        # Get inputs\n","        inputs, targets = data\n","\n","        # Generate outputs\n","        outputs = model(inputs)\n","\n","        # Set total and correct\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","      # Print accuracy\n","      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n","      print('--------------------------------')\n","      results[fold] = 100.0 * (correct / total)\n","    \n","# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","for key, value in results.items():\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","print(f'Average: {sum/len(results.items())} %')\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# losses is the list of losses generated during training\n","plt.plot([loss.detach().numpy() for loss in losses])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","plt.show()\n","# losses is the list of losses generated during training\n","plt.plot([acc.detach().numpy() for acc in accuracies])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Accuracy')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"Ot1aGrquFyki"},"source":["### Without Batch Normalization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sFdRth2GF2a4"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"yx8KHC8y6rCk"},"source":["## L1 and L2 regularization#"]},{"cell_type":"markdown","metadata":{"id":"HVLYDYpMGZ6B"},"source":["### L1 Regularization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oMphQEJMGdJP"},"outputs":[],"source":["\n","#  you can set epoch size\n","def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","k_folds = 3\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","# set the epoch\n","epochs = 15\n","\n","\n","# loop over the dataset multiple times\n","losses = []\n","accuracies = []\n","results = {}\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(train_set)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Sample elements randomly from a given list of ids, no replacement.\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    # Define data loaders for training and testing data in this fold\n","    trainloader = torch.utils.data.DataLoader(\n","                      train_set, \n","                      batch_size=10, sampler=train_subsampler)\n","    testloader = torch.utils.data.DataLoader(\n","                      train_set,\n","                      batch_size=10, sampler=test_subsampler)\n","    model = MLP()\n","    model.apply(reset_weights)\n","    # define learning rate\n","    learning_rate = 0.005\n","    # define your optimizer with SGD and learning rate\n","    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n","    # define the loss function\n","    criterion = nn.CrossEntropyLoss()\n","    for i in range(epochs):\n","      correct = 0\n","      training_start_time = time.time()\n","      for j,(images,targets) in enumerate(train_loader):\n","        l1_lambda = 0.001\n","        l1_reg = torch.tensor(0., requires_grad=True)\n","        for name, param in model.named_parameters():\n","            if 'weight' in name:\n","                l1_reg = l1_reg + torch.norm(param, 1)\n","        #making predictions\n","        y_pred = model(images)\n","        #calculating loss\n","        loss = criterion(y_pred,targets.reshape(-1))\n","        #backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        correct += (y_pred.argmax(axis = 1) == targets).float().sum()\n","      accuracy = 100 * correct / len(train_set)\n","      if i>10:\n","        optimizer.lr = 0.0005\n","      print(loss)\n","      print(accuracy)\n","      losses.append(loss)\n","      accuracies.append(accuracy)\n","\n","    print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n","    print(f'accuracy during training is {accuracy.item()}')\n","    print(f\"loss after training is {loss.item()}\")\n","     # Evaluationfor this fold\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","\n","      # Iterate over the test data and generate predictions\n","      for i, data in enumerate(testloader, 0):\n","\n","        # Get inputs\n","        inputs, targets = data\n","\n","        # Generate outputs\n","        outputs = model(inputs)\n","\n","        # Set total and correct\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","      # Print accuracy\n","      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n","      print('--------------------------------')\n","      results[fold] = 100.0 * (correct / total)\n","    \n","# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","for key, value in results.items():\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","print(f'Average: {sum/len(results.items())} %')\n","\n","print('Complete Training')\n","# losses is the list of losses generated during training\n","plt.plot([loss.detach().numpy() for loss in losses])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","plt.show()\n","# losses is the list of losses generated during training\n","plt.plot([acc.detach().numpy() for acc in accuracies])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Accuracy')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"WEjvU4XPGdvT"},"source":["### L2 Regularization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QT9tnxucGgJM"},"outputs":[],"source":["\n","#  you can set epoch sizedef reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","k_folds = 3\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","\n","# loop over the dataset multiple times\n","losses = []\n","accuracies = []\n","results = {}\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(train_set)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Sample elements randomly from a given list of ids, no replacement.\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    # Define data loaders for training and testing data in this fold\n","    trainloader = torch.utils.data.DataLoader(\n","                      train_set, \n","                      batch_size=10, sampler=train_subsampler)\n","    testloader = torch.utils.data.DataLoader(\n","                      train_set,\n","                      batch_size=10, sampler=test_subsampler)\n","    model = MLP()\n","    model.apply(reset_weights)\n","    # define learning rate\n","    learning_rate = 0.005\n","    # define your optimizer with SGD and learning rate\n","    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n","    # define the loss function\n","    criterion = nn.CrossEntropyLoss()\n","    for i in range(epochs):\n","      correct = 0\n","      training_start_time = time.time()\n","      for j,(images,targets) in enumerate(train_loader):\n","        l2_lambda = 0.01\n","        l2_reg = torch.tensor(0., requires_grad=True)\n","        for name, param in model.named_parameters():\n","            if 'weight' in name:\n","                l2_reg = l2_reg + torch.norm(param, 2)\n","        #making predictions\n","        y_pred = model(images)\n","        #calculating loss\n","        loss = criterion(y_pred,targets.reshape(-1))\n","        #backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        correct += (y_pred.argmax(axis = 1) == targets).float().sum()\n","      accuracy = 100 * correct / len(train_set)\n","      if i>10:\n","        optimizer.lr = 0.0005\n","      print(loss)\n","      print(accuracy)\n","      losses.append(loss)\n","      accuracies.append(accuracy)\n","\n","    print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n","    print(f'accuracy during training is {accuracy.item()}')\n","    print(f\"loss after training is {loss.item()}\")\n","     # Evaluationfor this fold\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","\n","      # Iterate over the test data and generate predictions\n","      for i, data in enumerate(testloader, 0):\n","\n","        # Get inputs\n","        inputs, targets = data\n","\n","        # Generate outputs\n","        outputs = model(inputs)\n","\n","        # Set total and correct\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","      # Print accuracy\n","      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n","      print('--------------------------------')\n","      results[fold] = 100.0 * (correct / total)\n","    \n","# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","for key, value in results.items():\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","print(f'Average: {sum/len(results.items())} %')\n","\n","\n","print('Complete Training')\n","# losses is the list of losses generated during training\n","plt.plot([loss.detach().numpy() for loss in losses])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","plt.show()\n","# losses is the list of losses generated during training\n","plt.plot([acc.detach().numpy() for acc in accuracies])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Accuracy')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"P9fPuJU_6vn8"},"source":["## Dropout"]},{"cell_type":"markdown","metadata":{"id":"lIMYC3tpGi3M"},"source":["### With Dropout"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uQccQ8ej_3Jk"},"outputs":[],"source":["# Baseline Model\n","class MLP(nn.Module):\n","    def __init__(self):\n","        super(MLP, self).__init__()\n","        self.flatten = nn.Flatten()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Dropout(0.2),\n","            nn.Linear(28*28, 512),\n","            nn.BatchNorm1d(256),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.BatchNorm1d(256),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.BatchNorm1d(256),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.BatchNorm1d(256),\n","            nn.ReLU(),\n","            nn.Linear(512, 47),\n","        )\n","\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","\n","# define the model\n","model_dropout = MLP()\n","\n","print(model_dropout)     \n","\n","#  you can set epoch size\n","def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","k_folds = 3\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","# set the epoch\n","epochs = 15\n","\n","\n","# loop over the dataset multiple times\n","losses = []\n","accuracies = []\n","results = {}\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(train_set)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Sample elements randomly from a given list of ids, no replacement.\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    # Define data loaders for training and testing data in this fold\n","    trainloader = torch.utils.data.DataLoader(\n","                      train_set, \n","                      batch_size=10, sampler=train_subsampler)\n","    testloader = torch.utils.data.DataLoader(\n","                      train_set,\n","                      batch_size=10, sampler=test_subsampler)\n","    model = MLP()\n","    model.apply(reset_weights)\n","    # define learning rate\n","    learning_rate = 0.005\n","    # define your optimizer with SGD and learning rate\n","    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n","    # define the loss function\n","    criterion = nn.CrossEntropyLoss()\n","    for i in range(epochs):\n","      correct = 0\n","      training_start_time = time.time()\n","      for j,(images,targets) in enumerate(train_loader):\n","        #making predictions\n","        y_pred = model(images)\n","        #calculating loss\n","        loss = criterion(y_pred,targets.reshape(-1))\n","        #backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        correct += (y_pred.argmax(axis = 1) == targets).float().sum()\n","      accuracy = 100 * correct / len(train_set)\n","      if i>10:\n","        optimizer.lr = 0.0005\n","      print(loss)\n","      print(accuracy)\n","      losses.append(loss)\n","      accuracies.append(accuracy)\n","\n","    print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n","    print(f'accuracy during training is {accuracy.item()}')\n","    print(f\"loss after training is {loss.item()}\")\n","     # Evaluationfor this fold\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","\n","      # Iterate over the test data and generate predictions\n","      for i, data in enumerate(testloader, 0):\n","\n","        # Get inputs\n","        inputs, targets = data\n","\n","        # Generate outputs\n","        outputs = model(inputs)\n","\n","        # Set total and correct\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","      # Print accuracy\n","      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n","      print('--------------------------------')\n","      results[fold] = 100.0 * (correct / total)\n","    \n","# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","for key, value in results.items():\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","print(f'Average: {sum/len(results.items())} %')\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# losses is the list of losses generated during training\n","plt.plot([loss.detach().numpy() for loss in losses])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","plt.show()\n","# losses is the list of losses generated during training\n","plt.plot([acc.detach().numpy() for acc in accuracies])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Accuracy')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C1Y2q_Cbezl6"},"outputs":[],"source":["# Test the result on test data\n","\n","# make a prediction for a sample randomly chose from the test dataset\n","# you can run this part repeatedly, see the classification result from the model\n","import random\n","rand_no = random.randint(0,10000)\n","print(rand_no)\n","\n","x_test,y_test = next(iter(test_loader))\n","\n","y_pred = (model(x_test).argmax(dim=1))\n","\n","plt.imshow(x_test[rand_no].reshape(28,28),cmap='gray')\n","\n","pred = model(x_test[rand_no].reshape(-1,1,28,28)).argmax()\n","\n","print(\"Prediction is {}\".format(pred))\n","\n","# compute the accuracy\n","\n","\n","\n","# compute the accuracy of the model\n","\n","print(\"Accuracy is : \",(y_pred.eq(y_test).sum()/test_size).item()*100,\"%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gPnxUmhUe6fT"},"outputs":[],"source":["# Visulize some test figures\n","figure = plt.figure(figsize=(10, 10))\n","cols, rows = 6, 5\n","for i in range(1, cols * rows + 1):\n","    sample_idx = torch.randint(len(test_set), size=(1,)).item()\n","    print(\"Prediction: {}\".format(sample_idx))\n","    img, label = test_set[sample_idx]\n","    # print(img.shape)\n","    pred = model(img.reshape(-1,1,28,28)).argmax()\n","    figure.add_subplot(rows, cols, i)\n","    # plt.title(\"Label \"+ str(label))\n","    plt.title(\"Prediction: {}\".format(pred))\n","    \n","    plt.axis(\"off\")\n","    plt.imshow(img.squeeze(), cmap=\"gray\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"80jU6b9IfI93"},"outputs":[],"source":["# we also can plot the Confusion Matrix\n","import pandas as pd\n","import torch.nn.functional as F\n","\n","# accuracy function \n","def testing_accuracy(model, data_loader):\n","    model.eval()\n","    test_loss = 0\n","    device = 'cpu'\n","\n","    y_pred = []\n","    y_actu = []\n","    with torch.no_grad():\n","        for data, target in data_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n","            # get the index of the max log-probability\n","            pred = output.argmax(dim=1, keepdim=True)\n","            y_pred.extend(torch.flatten(pred).tolist()) \n","            y_actu.extend(target.tolist())\n","           \n","    y_pred = pd.Series(y_pred, name='Actual')\n","    y_actu = pd.Series(y_actu, name='Predicted')\n","    cm = pd.crosstab(y_actu, y_pred)\n","    correct = sum([cm.iloc[i,i] for i in range(len(cm))])\n","    \n","    test_loss /= len(data_loader.dataset)\n","    accuracy = 100*correct/len(test_loader.dataset)\n","\n","    return(test_loss, accuracy, cm)\n","\n","test_results = testing_accuracy(model, test_loader)\n","\n","print(\"- Test Loss: \", test_results[0], \"\\n\")\n","print(\"- Accuracy: \", test_results[1], \"\\n\")\n","print(\"- Confusion Matrix: \\n \\n\",  test_results[2] )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gnq8EvGEfMf6"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","conf_matrix = test_results[2].to_numpy()\n","\n","fig, ax = plt.subplots(figsize=(10,6))\n","im = ax.imshow(conf_matrix)\n","\n","ax.set_xticks(np.arange(10))\n","ax.set_yticks(np.arange(10))\n","\n","for i in range(conf_matrix.shape[0]):\n","    for j in range(conf_matrix.shape[1]):\n","        text = ax.text(j, i, conf_matrix[i, j],\n","                       ha=\"center\", va=\"center\", color=\"w\")\n","        \n","ax.set_xlabel('Actual Labels')\n","ax.set_ylabel('Predicted Labels')\n","ax.set_title('Confusion Matrix')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jq1SdqthfRpm"},"outputs":[],"source":["#  train on the GPU\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","# Assuming that we are on a CUDA machine, this should print a CUDA device:\n","print(device)\n","\n","\n","# save the training model\n","PATH = './mnist_net.pth'\n","torch.save(model.state_dict(), PATH)\n"]},{"cell_type":"markdown","metadata":{"id":"0Hw1DvJyTJDJ"},"source":["# CNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iPepsxD6TKuZ"},"outputs":[],"source":["epochs = 15\n","# define the model\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(1,10,5)    # Convolutional layer\n","        self.conv2 = nn.Conv2d(10,20,3)\n","\n","        self.fc1 = nn.Linear(20*10*10,500)\n","        self.fc2 = nn.Linear(500, 47)\n","\n","    def forward(self, x):     \n","        input_size = x.size(0)\n","        # in: batch*1*28*28, out: batch*10*24*24(28-5+1)\n","        x = self.conv1(x)\n","        # out: batch*10*24*24\n","        x = F.relu(x)\n","        # in: batch*10*24*24, out: batch*10*12*12\n","        x = F.max_pool2d(x,2,2)\n","\n","        # in: batch*10*12*12, out: batch*20*10*10 (12-3+1)\n","        x = self.conv2(x)\n","        x = F.relu(x)\n","\n","        # 20*10*10 = 2000\n","        x = x.view(input_size,-1)\n","\n","        # in: batch*2000  out:batch*500\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","\n","        # in:batch*500 out:batch*10\n","        x = self.fc2(x)\n","        return F.log_softmax(x)\n","    \n","# create the object for model CNN\n","net= CNN()\n","print(net)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m1dE4NfJivoZ"},"outputs":[],"source":["# define the parameters\n","learning_rate = 1e-3\n","batch_size = 60\n","\n","#loss = F.nll_loss(output, target)\n","optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n","# optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate) # Stochastic Gradient Descent\n","\n","print(len(train_loader.dataset))\n","print(len(test_loader.dataset))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"orz02dxCi2LG"},"outputs":[],"source":["#  train the model\n","correct = 0\n","loss_list = []\n","accuracy_list = []\n","for i in range(1,epochs+1):\n","   print(f\"Epoch {i}\\n-------------------------------\")\n","   net.train()\n","   for batch_idx, (data, target) in enumerate(train_loader):\n","      \n","      optimizer.zero_grad()\n","      output = net(data)\n","      \n","      loss = F.nll_loss(output, target) # negative log likelihood loss used for classification\n","      loss.backward()\n","      optimizer.step()\n","   loss_list.append(loss.data)\n","   print('iteration: {}, \\t loss: {}'.format(i, loss.item()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bPOAGW89jFAH"},"outputs":[],"source":["# plot the figure \n","fig = plt.figure(figsize=(20, 10))\n","\n","plt.plot(loss_list)\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5hmO4HLBjUio"},"outputs":[],"source":["correct = 0\n","# x_test,y_test = next(iter(test_loader))\n","# print(len(x_test))\n","\n","for data, target in test_loader:\n","\n","    outputs = net(data)\n","    _, predicted = torch.max(outputs.data, 1)\n","\n","    correct += (predicted == target).sum().item()\n","\n","    print('Test accuracy: {}/{} ({:.0f}%)\\n'.format(correct, len(test_loader.dataset),\n","                                                    100. * correct / len(test_loader.dataset)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CvehOM8lleQj"},"outputs":[],"source":["# save the training model\n","PATH2 = './mnist_net_CNN.pth'\n","torch.save(net.state_dict(), PATH2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kduPTjdil92Y"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"hAsWY54v4mBH"},"source":["## Loss function and Accuracy Graph\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VyMAhe9V4mBI"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# losses is the list of losses generated during training\n","plt.plot([loss.detach().numpy() for loss in losses])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","plt.show()\n","# losses is the list of losses generated during training\n","plt.plot([acc.detach().numpy() for acc in accuracies])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Accuracy')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"MU-cW-Fv4mBI"},"source":["## Adaptive Learning rate"]},{"cell_type":"markdown","metadata":{"id":"IS6TmoE54mBI"},"source":["### Step based scheduler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8pydVhei4mBI"},"outputs":[],"source":["# #  you can set epoch size\n","\n","# # define learning rate\n","# learning_rate = 0.05\n","# # define your optimizer with SGD and learning rate\n","# optimizer = torch.optim.SGD(net.parameters(),lr=learning_rate)\n","# # define the loss function\n","# criterion = nn.CrossEntropyLoss()\n","# # Step based scheduling method\n","# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n","# lrs = []\n","\n","\n","\n","# # loop over the dataset multiple times\n","# losses = []\n","# accuracies = []\n","# for i in range(epochs):\n","#   correct = 0\n","#   for j,(images,targets) in enumerate(train_loader):\n","    \n","#     #making predictions\n","#     y_pred = net(images)\n","#     # print(f'predictions are {y_pred.argmax(axis = 1)}')\n","#     # print(f'targets are {targets}')\n","#     #calculating loss\n","#     loss = criterion(y_pred,targets.reshape(-1))\n","#     #backprop\n","#     optimizer.zero_grad()\n","#     loss.backward()\n","#     optimizer.step()\n","#     correct += (y_pred.argmax(axis = 1) == targets).float().sum()\n","#   scheduler.step()\n","#   lrs.append(optimizer.param_groups[0][\"lr\"])\n","#   accuracy = 100 * correct / len(train_set)\n","#   # if i>10:\n","#   #   optimizer.lr = 0.0005\n","#   print(loss)\n","#   print(accuracy)\n","#   losses.append(loss)\n","#   accuracies.append(accuracy)\n","\n","# print('Complete Training')\n","# import numpy as np\n","# import matplotlib.pyplot as plt\n","\n","# # losses is the list of losses generated during training\n","# plt.plot([loss.detach().numpy() for loss in losses])\n","# plt.xlabel('Epoch')\n","# plt.ylabel('Loss')\n","# plt.title('Training Loss')\n","# plt.show()\n","# # losses is the list of losses generated during training\n","# plt.plot([acc.detach().numpy() for acc in accuracies])\n","# plt.xlabel('Epoch')\n","# plt.ylabel('Loss')\n","# plt.title('Accuracy')\n","# plt.show()\n","\n","# plt.plot([lr for lr in lrs])\n","# plt.show()\n","\n","# print(lrs)\n","print(lrs)\n","import numpy as np\n","import matplotlib.pyplot as plt\n","#  you can set epoch size\n","epochs = 15\n","lrs = []\n","\n","\n","\n","# loop over the dataset multiple times\n","losses = []\n","accuracies = []\n","#  you can set epoch size\n","def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","k_folds = 3\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","results = {}\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(train_set)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Sample elements randomly from a given list of ids, no replacement.\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    # Define data loaders for training and testing data in this fold\n","    trainloader = torch.utils.data.DataLoader(\n","                      train_set, \n","                      batch_size=10, sampler=train_subsampler)\n","    testloader = torch.utils.data.DataLoader(\n","                      train_set,\n","                      batch_size=10, sampler=test_subsampler)\n","    model = CNN()\n","    model.apply(reset_weights)\n","    # define learning rate\n","    learning_rate = 0.05\n","    # define your optimizer with SGD and learning rate\n","    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n","    # define the loss function\n","    criterion = nn.CrossEntropyLoss()\n","    # Step based scheduling method\n","    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n","    for i in range(epochs):\n","      correct = 0\n","      for j,(images,targets) in enumerate(train_loader):\n","        \n","        #making predictions\n","        y_pred = model(images)\n","        #calculating loss\n","        loss = criterion(y_pred,targets.reshape(-1))\n","        #backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        correct += (y_pred.argmax(axis = 1) == targets).float().sum()\n","      scheduler.step()\n","      lrs.append(optimizer.param_groups[0][\"lr\"])\n","      accuracy = 100 * correct / len(train_set)\n","      # if i>10:\n","      #   optimizer.lr = 0.0005\n","      print(loss)\n","      print(accuracy)\n","      losses.append(loss)\n","      accuracies.append(accuracy)\n","\n","    print('Complete Training')\n","\n","    print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n","    print(f'accuracy during training is {accuracy.item()}')\n","    print(f\"loss after training is {loss.item()}\")\n","     # Evaluationfor this fold\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","\n","      # Iterate over the test data and generate predictions\n","      for i, data in enumerate(testloader, 0):\n","\n","        # Get inputs\n","        inputs, targets = data\n","\n","        # Generate outputs\n","        outputs = model(inputs)\n","\n","        # Set total and correct\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","      # Print accuracy\n","      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n","      print('--------------------------------')\n","      results[fold] = 100.0 * (correct / total)\n","    \n","# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","for key, value in results.items():\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","print(f'Average: {sum/len(results.items())} %')\n","# losses is the list of losses generated during training\n","plt.plot([loss.detach().numpy() for loss in losses])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","plt.show()\n","# losses is the list of losses generated during training\n","plt.plot([acc.detach().numpy() for acc in accuracies])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Accuracy')\n","plt.show()\n","\n","plt.plot([lr for lr in lrs])\n","plt.show()\n","\n","print(lrs)"]},{"cell_type":"markdown","metadata":{"id":"iJXeH0pU4mBI"},"source":["### Exponenential scheduler"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wbMMP-Io4mBI"},"outputs":[],"source":["# #  you can set epoch size\n","\n","# # define learning rate\n","# learning_rate = 0.05\n","# # define your optimizer with SGD and learning rate\n","# optimizer = torch.optim.SGD(net.parameters(),lr=learning_rate)\n","# # define the loss function\n","# criterion = nn.CrossEntropyLoss()\n","# # set the epoch\n","# # Step based scheduling method\n","# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)\n","# lrs = []\n","\n","\n","\n","# # loop over the dataset multiple times\n","# losses = []\n","# accuracies = []\n","# for i in range(epochs):\n","#   correct = 0\n","#   for j,(images,targets) in enumerate(train_loader):\n","    \n","#     #making predictions\n","#     y_pred = net(images)\n","#     # print(f'predictions are {y_pred.argmax(axis = 1)}')\n","#     # print(f'targets are {targets}')\n","#     #calculating loss\n","#     loss = criterion(y_pred,targets.reshape(-1))\n","#     #backprop\n","#     optimizer.zero_grad()\n","#     loss.backward()\n","#     optimizer.step()\n","#     lrs.append(optimizer.param_groups[0][\"lr\"])\n","#     correct += (y_pred.argmax(axis = 1) == targets).float().sum()\n","#   scheduler.step()\n","#   accuracy = 100 * correct / len(train_set)\n","#   # if i>10:\n","#   #   optimizer.lr = 0.0005\n","#   print(loss)\n","#   print(accuracy)\n","#   losses.append(loss)\n","#   accuracies.append(accuracy)\n","\n","# print('Complete Training')\n","# import numpy as np\n","# import matplotlib.pyplot as plt\n","\n","# # losses is the list of losses generated during training\n","# plt.plot([loss.detach().numpy() for loss in losses])\n","# plt.xlabel('Epoch')\n","# plt.ylabel('Loss')\n","# plt.title('Training Loss')\n","# plt.show()\n","# # losses is the list of losses generated during training\n","# plt.plot([acc.detach().numpy() for acc in accuracies])\n","# plt.xlabel('Epoch')\n","# plt.ylabel('Loss')\n","# plt.title('Accuracy')\n","# plt.show()\n","\n","# plt.plot([lr for lr in lrs])\n","# plt.show()\n","#  you can set epoch size\n","\n","# define learning rate\n","learning_rate = 0.05\n","lrs = []\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","#  you can set epoch size\n","# loop over the dataset multiple times\n","losses = []\n","accuracies = []\n","#  you can set epoch size\n","def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","k_folds = 5\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","results = {}\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(train_set)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Sample elements randomly from a given list of ids, no replacement.\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    # Define data loaders for training and testing data in this fold\n","    trainloader = torch.utils.data.DataLoader(\n","                      train_set, \n","                      batch_size=10, sampler=train_subsampler)\n","    testloader = torch.utils.data.DataLoader(\n","                      train_set,\n","                      batch_size=10, sampler=test_subsampler)\n","    model = CNN()\n","    model.apply(reset_weights)\n","    # define your optimizer with SGD and learning rate\n","    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n","    # define the loss function\n","    criterion = nn.CrossEntropyLoss()\n","    # set the epoch\n","    # Step based scheduling method\n","    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.1)\n","    for i in range(epochs):\n","      correct = 0\n","      for j,(images,targets) in enumerate(train_loader):\n","        \n","        #making predictions\n","        y_pred = model(images)\n","        #calculating loss\n","        loss = criterion(y_pred,targets.reshape(-1))\n","        #backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        lrs.append(optimizer.param_groups[0][\"lr\"])\n","        correct += (y_pred.argmax(axis = 1) == targets).float().sum()\n","      scheduler.step()\n","      accuracy = 100 * correct / len(train_set)\n","      # if i>10:\n","      #   optimizer.lr = 0.0005\n","      print(loss)\n","      print(accuracy)\n","      losses.append(loss)\n","      accuracies.append(accuracy)\n","\n","    print('Complete Training')\n","\n","    print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n","     # Evaluationfor this fold\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","\n","      # Iterate over the test data and generate predictions\n","      for i, data in enumerate(testloader, 0):\n","\n","        # Get inputs\n","        inputs, targets = data\n","\n","        # Generate outputs\n","        outputs = model(inputs)\n","\n","        # Set total and correct\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","      # Print accuracy\n","      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n","      print('--------------------------------')\n","      results[fold] = 100.0 * (correct / total)\n","    \n","# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","for key, value in results.items():\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","print(f'Average: {sum/len(results.items())} %')\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# losses is the list of losses generated during training\n","plt.plot([loss.detach().numpy() for loss in losses])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","plt.show()\n","# losses is the list of losses generated during training\n","plt.plot([acc.detach().numpy() for acc in accuracies])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Accuracy')\n","plt.show()\n","\n","plt.plot([lr for lr in lrs])\n","plt.show()\n","\n","print(lrs)"]},{"cell_type":"markdown","metadata":{"id":"tqcIxcP54mBJ"},"source":["## Activation function"]},{"cell_type":"markdown","metadata":{"id":"mtlmfsr64mBJ"},"source":["### Leaky Relu"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MSnsKkP-4mBJ"},"outputs":[],"source":["class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(1,10,5)    # Convolutional layer\n","        self.conv2 = nn.Conv2d(10,20,3)\n","\n","        self.fc1 = nn.Linear(20*10*10,500)\n","        self.fc2 = nn.Linear(500, 47)\n","\n","    def forward(self, x):     \n","        input_size = x.size(0)\n","        # in: batch*1*28*28, out: batch*10*24*24(28-5+1)\n","        x = self.conv1(x)\n","        # out: batch*10*24*24\n","        x = F.leaky_relu(x)\n","        # in: batch*10*24*24, out: batch*10*12*12\n","        x = F.max_pool2d(x,2,2)\n","\n","        # in: batch*10*12*12, out: batch*20*10*10 (12-3+1)\n","        x = self.conv2(x)\n","        x = F.leaky_relu(x)\n","\n","        # 20*10*10 = 2000\n","        x = x.view(input_size,-1)\n","\n","        # in: batch*2000  out:batch*500\n","        x = self.fc1(x)\n","        x = F.leaky_relu(x)\n","\n","        # in:batch*500 out:batch*10\n","        x = self.fc2(x)\n","        return F.log_softmax(x)\n","    \n","# define the model\n","model_leaky = CNN()\n","print(model_leaky)\n","#  you can set epoch size\n","def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","k_folds = 5\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","# set the epoch\n","epochs = 3\n","\n","\n","# loop over the dataset multiple times\n","losses = []\n","accuracies = []\n","results = {}\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(train_set)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Sample elements randomly from a given list of ids, no replacement.\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    # Define data loaders for training and testing data in this fold\n","    trainloader = torch.utils.data.DataLoader(\n","                      train_set, \n","                      batch_size=10, sampler=train_subsampler)\n","    testloader = torch.utils.data.DataLoader(\n","                      train_set,\n","                      batch_size=10, sampler=test_subsampler)\n","    model = CNN()\n","    model.apply(reset_weights)\n","    # define learning rate\n","    learning_rate = 0.005\n","    # define your optimizer with SGD and learning rate\n","    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n","    # define the loss function\n","    criterion = nn.CrossEntropyLoss()\n","    for i in range(epochs):\n","      correct = 0\n","      training_start_time = time.time()\n","      for j,(images,targets) in enumerate(train_loader):\n","        #making predictions\n","        y_pred = model(images)\n","        #calculating loss\n","        loss = criterion(y_pred,targets.reshape(-1))\n","        #backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        correct += (y_pred.argmax(axis = 1) == targets).float().sum()\n","      accuracy = 100 * correct / len(train_set)\n","      if i>10:\n","        optimizer.lr = 0.0005\n","      print(loss)\n","      print(accuracy)\n","      losses.append(loss)\n","      accuracies.append(accuracy)\n","\n","    print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n","     # Evaluationfor this fold\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","\n","      # Iterate over the test data and generate predictions\n","      for i, data in enumerate(testloader, 0):\n","\n","        # Get inputs\n","        inputs, targets = data\n","\n","        # Generate outputs\n","        outputs = model(inputs)\n","\n","        # Set total and correct\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","      # Print accuracy\n","      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n","      print('--------------------------------')\n","      results[fold] = 100.0 * (correct / total)\n","    \n","# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","for key, value in results.items():\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","print(f'Average: {sum/len(results.items())} %')\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# losses is the list of losses generated during training\n","plt.plot([loss.detach().numpy() for loss in losses])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","plt.show()\n","# losses is the list of losses generated during training\n","plt.plot([acc.detach().numpy() for acc in accuracies])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Accuracy')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"4EATpMRr4mBJ"},"source":["### ELU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1G26fPp44mBJ"},"outputs":[],"source":["class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(1,10,5)    # Convolutional layer\n","        self.conv2 = nn.Conv2d(10,20,3)\n","\n","        self.fc1 = nn.Linear(20*10*10,500)\n","        self.fc2 = nn.Linear(500, 47)\n","\n","    def forward(self, x):     \n","        input_size = x.size(0)\n","        # in: batch*1*28*28, out: batch*10*24*24(28-5+1)\n","        x = self.conv1(x)\n","        # out: batch*10*24*24\n","        x = F.elu(x)\n","        # in: batch*10*24*24, out: batch*10*12*12\n","        x = F.max_pool2d(x,2,2)\n","\n","        # in: batch*10*12*12, out: batch*20*10*10 (12-3+1)\n","        x = self.conv2(x)\n","        x = F.elu(x)\n","\n","        # 20*10*10 = 2000\n","        x = x.view(input_size,-1)\n","\n","        # in: batch*2000  out:batch*500\n","        x = self.fc1(x)\n","        x = F.elu(x)\n","\n","        # in:batch*500 out:batch*10\n","        x = self.fc2(x)\n","        return F.log_softmax(x)\n","    \n","# define the model\n","model_elu = CNN()\n","\n","print(model_elu)\n","#  you can set epoch size\n","def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","k_folds = 5\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","# set the epoch\n","epochs = 3\n","\n","\n","# loop over the dataset multiple times\n","losses = []\n","accuracies = []\n","results = {}\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(train_set)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Sample elements randomly from a given list of ids, no replacement.\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    # Define data loaders for training and testing data in this fold\n","    trainloader = torch.utils.data.DataLoader(\n","                      train_set, \n","                      batch_size=10, sampler=train_subsampler)\n","    testloader = torch.utils.data.DataLoader(\n","                      train_set,\n","                      batch_size=10, sampler=test_subsampler)\n","    model = CNN()\n","    model.apply(reset_weights)\n","    # define learning rate\n","    learning_rate = 0.005\n","    # define your optimizer with SGD and learning rate\n","    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n","    # define the loss function\n","    criterion = nn.CrossEntropyLoss()\n","    for i in range(epochs):\n","      correct = 0\n","      training_start_time = time.time()\n","      for j,(images,targets) in enumerate(train_loader):\n","        #making predictions\n","        y_pred = model(images)\n","        #calculating loss\n","        loss = criterion(y_pred,targets.reshape(-1))\n","        #backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        correct += (y_pred.argmax(axis = 1) == targets).float().sum()\n","      accuracy = 100 * correct / len(train_set)\n","      if i>10:\n","        optimizer.lr = 0.0005\n","      print(loss)\n","      print(accuracy)\n","      losses.append(loss)\n","      accuracies.append(accuracy)\n","\n","    print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n","     # Evaluationfor this fold\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","\n","      # Iterate over the test data and generate predictions\n","      for i, data in enumerate(testloader, 0):\n","\n","        # Get inputs\n","        inputs, targets = data\n","\n","        # Generate outputs\n","        outputs = model(inputs)\n","\n","        # Set total and correct\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","      # Print accuracy\n","      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n","      print('--------------------------------')\n","      results[fold] = 100.0 * (correct / total)\n","    \n","# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","for key, value in results.items():\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","print(f'Average: {sum/len(results.items())} %')\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# losses is the list of losses generated during training\n","plt.plot([loss.detach().numpy() for loss in losses])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","plt.show()\n","# losses is the list of losses generated during training\n","plt.plot([acc.detach().numpy() for acc in accuracies])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Accuracy')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"KQFXJcfO4mBK"},"source":["### SELU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0huv--iF4mBK"},"outputs":[],"source":["class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(1,10,5)    # Convolutional layer\n","        self.conv2 = nn.Conv2d(10,20,3)\n","\n","        self.fc1 = nn.Linear(20*10*10,500)\n","        self.fc2 = nn.Linear(500, 47)\n","\n","    def forward(self, x):     \n","        input_size = x.size(0)\n","        # in: batch*1*28*28, out: batch*10*24*24(28-5+1)\n","        x = self.conv1(x)\n","        # out: batch*10*24*24\n","        x = F.selu(x)\n","        # in: batch*10*24*24, out: batch*10*12*12\n","        x = F.max_pool2d(x,2,2)\n","\n","        # in: batch*10*12*12, out: batch*20*10*10 (12-3+1)\n","        x = self.conv2(x)\n","        x = F.selu(x)\n","\n","        # 20*10*10 = 2000\n","        x = x.view(input_size,-1)\n","\n","        # in: batch*2000  out:batch*500\n","        x = self.fc1(x)\n","        x = F.selu(x)\n","\n","        # in:batch*500 out:batch*10\n","        x = self.fc2(x)\n","        return F.log_softmax(x)\n","    \n","# define the model\n","model_selu = CNN()\n","\n","print(model_selu)\n","#  you can set epoch size\n","def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","k_folds = 5\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","# set the epoch\n","epochs = 3\n","\n","\n","# loop over the dataset multiple times\n","losses = []\n","accuracies = []\n","results = {}\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(train_set)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Sample elements randomly from a given list of ids, no replacement.\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    # Define data loaders for training and testing data in this fold\n","    trainloader = torch.utils.data.DataLoader(\n","                      train_set, \n","                      batch_size=10, sampler=train_subsampler)\n","    testloader = torch.utils.data.DataLoader(\n","                      train_set,\n","                      batch_size=10, sampler=test_subsampler)\n","    model = CNN()\n","    model.apply(reset_weights)\n","    # define learning rate\n","    learning_rate = 0.005\n","    # define your optimizer with SGD and learning rate\n","    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n","    # define the loss function\n","    criterion = nn.CrossEntropyLoss()\n","    for i in range(epochs):\n","      correct = 0\n","      training_start_time = time.time()\n","      for j,(images,targets) in enumerate(train_loader):\n","        #making predictions\n","        y_pred = model(images)\n","        #calculating loss\n","        loss = criterion(y_pred,targets.reshape(-1))\n","        #backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        correct += (y_pred.argmax(axis = 1) == targets).float().sum()\n","      accuracy = 100 * correct / len(train_set)\n","      if i>10:\n","        optimizer.lr = 0.0005\n","      print(loss)\n","      print(accuracy)\n","      losses.append(loss)\n","      accuracies.append(accuracy)\n","\n","    print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n","     # Evaluationfor this fold\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","\n","      # Iterate over the test data and generate predictions\n","      for i, data in enumerate(testloader, 0):\n","\n","        # Get inputs\n","        inputs, targets = data\n","\n","        # Generate outputs\n","        outputs = model(inputs)\n","\n","        # Set total and correct\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","      # Print accuracy\n","      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n","      print('--------------------------------')\n","      results[fold] = 100.0 * (correct / total)\n","    \n","# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","for key, value in results.items():\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","print(f'Average: {sum/len(results.items())} %')\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# losses is the list of losses generated during training\n","plt.plot([loss.detach().numpy() for loss in losses])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","plt.show()\n","# losses is the list of losses generated during training\n","plt.plot([acc.detach().numpy() for acc in accuracies])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Accuracy')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"DI1zEFTy4mBK"},"source":["## Optimizers"]},{"cell_type":"markdown","metadata":{"id":"_Al3t1-s4mBK"},"source":["### Adam"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R0QII4rM4mBK"},"outputs":[],"source":["#  you can set epoch size\n","def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","model = CNN()\n","# define the loss function\n","criterion = nn.CrossEntropyLoss()\n","\n","\n","# loop over the dataset multiple times\n","losses = []\n","accuracies = []\n","results = {}\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(train_set)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Sample elements randomly from a given list of ids, no replacement.\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    # Define data loaders for training and testing data in this fold\n","    trainloader = torch.utils.data.DataLoader(\n","                      train_set, \n","                      batch_size=10, sampler=train_subsampler)\n","    testloader = torch.utils.data.DataLoader(\n","                      train_set,\n","                      batch_size=10, sampler=test_subsampler)\n","    model = CNN()\n","    model.apply(reset_weights)\n","    k_folds = 3\n","    kfold = KFold(n_splits=k_folds, shuffle=True)\n","    # define learning rate\n","    learning_rate = 0.005\n","    # define your optimizer with SGD and learning rate\n","    optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n","    for i in range(epochs):\n","      correct = 0\n","      training_start_time = time.time()\n","      for j,(images,targets) in enumerate(train_loader):\n","        #making predictions\n","        y_pred = model(images)\n","        #calculating loss\n","        loss = criterion(y_pred,targets.reshape(-1))\n","        #backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        correct += (y_pred.argmax(axis = 1) == targets).float().sum()\n","      accuracy = 100 * correct / len(train_set)\n","      if i>10:\n","        optimizer.lr = 0.0005\n","      print(loss)\n","      print(accuracy)\n","      losses.append(loss)\n","      accuracies.append(accuracy)\n","\n","    print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n","    print(f'accuracy during training is {accuracy.item()}')\n","     # Evaluationfor this fold\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","\n","      # Iterate over the test data and generate predictions\n","      for i, data in enumerate(testloader, 0):\n","\n","        # Get inputs\n","        inputs, targets = data\n","\n","        # Generate outputs\n","        outputs = model(inputs)\n","\n","        # Set total and correct\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","      # Print accuracy\n","      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n","      print('--------------------------------')\n","      results[fold] = 100.0 * (correct / total)\n","    \n","# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","for key, value in results.items():\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","print(f'Average: {sum/len(results.items())} %')\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# losses is the list of losses generated during training\n","plt.plot([loss.detach().numpy() for loss in losses])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","plt.show()\n","# losses is the list of losses generated during training\n","plt.plot([acc.detach().numpy() for acc in accuracies])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Accuracy')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"pUsKzxYD4mBK"},"source":["### Adagrad"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EANpnqsG4mBK"},"outputs":[],"source":["#  you can set epoch size\n","def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","model = CNN()\n","k_folds = 3\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","\n","\n","# loop over the dataset multiple times\n","losses = []\n","accuracies = []\n","results = {}\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(train_set)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Sample elements randomly from a given list of ids, no replacement.\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    # Define data loaders for training and testing data in this fold\n","    trainloader = torch.utils.data.DataLoader(\n","                      train_set, \n","                      batch_size=10, sampler=train_subsampler)\n","    testloader = torch.utils.data.DataLoader(\n","                      train_set,\n","                      batch_size=10, sampler=test_subsampler)\n","    model = CNN()\n","    model.apply(reset_weights)\n","    # define learning rate\n","    learning_rate = 0.005\n","    # define your optimizer with SGD and learning rate\n","    optimizer = torch.optim.Adagrad(model.parameters(),lr=learning_rate)\n","    # define the loss function\n","    criterion = nn.CrossEntropyLoss()\n","    for i in range(epochs):\n","      correct = 0\n","      training_start_time = time.time()\n","      for j,(images,targets) in enumerate(train_loader):\n","        #making predictions\n","        y_pred = model(images)\n","        #calculating loss\n","        loss = criterion(y_pred,targets.reshape(-1))\n","        #backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        correct += (y_pred.argmax(axis = 1) == targets).float().sum()\n","      accuracy = 100 * correct / len(train_set)\n","      if i>10:\n","        optimizer.lr = 0.0005\n","      print(loss)\n","      print(accuracy)\n","      losses.append(loss)\n","      accuracies.append(accuracy)\n","\n","    print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n","    print(f'accuracy during training is {accuracy.item()}')\n","     # Evaluationfor this fold\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","\n","      # Iterate over the test data and generate predictions\n","      for i, data in enumerate(testloader, 0):\n","\n","        # Get inputs\n","        inputs, targets = data\n","\n","        # Generate outputs\n","        outputs = model(inputs)\n","\n","        # Set total and correct\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","      # Print accuracy\n","      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n","      print('--------------------------------')\n","      results[fold] = 100.0 * (correct / total)\n","    \n","# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","for key, value in results.items():\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","print(f'Average: {sum/len(results.items())} %')\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# losses is the list of losses generated during training\n","plt.plot([loss.detach().numpy() for loss in losses])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","plt.show()\n","# losses is the list of losses generated during training\n","plt.plot([acc.detach().numpy() for acc in accuracies])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Accuracy')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"QQRbm-7H4mBL"},"source":["## Batch Normalization"]},{"cell_type":"markdown","metadata":{"id":"Lwzjp2QX4mBL"},"source":["### With Batch Normalization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ebtj6FII4mBL"},"outputs":[],"source":["# Baseline Model\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(1,10,5)    # Convolutional layer\n","        self.bn1 = nn.BatchNorm2d(10) \n","        self.conv2 = nn.Conv2d(10,20,3)\n","\n","        self.fc1 = nn.Linear(20*10*10,500)\n","        self.bn3 = nn.BatchNorm1d(500)\n","        self.fc2 = nn.Linear(500, 47)\n","\n","    def forward(self, x):     \n","        input_size = x.size(0)\n","        # in: batch*1*28*28, out: batch*10*24*24(28-5+1)\n","        x = self.conv1(x)\n","        # out: batch*10*24*24\n","        x = F.relu(x)\n","        # in: batch*10*24*24, out: batch*10*12*12\n","        x = F.max_pool2d(x,2,2)\n","\n","        # in: batch*10*12*12, out: batch*20*10*10 (12-3+1)\n","        x = self.conv2(x)\n","        x = F.relu(x)\n","\n","        # 20*10*10 = 2000\n","        x = x.view(input_size,-1)\n","\n","        # in: batch*2000  out:batch*500\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","\n","        # in:batch*500 out:batch*10\n","        x = self.fc2(x)\n","        return F.log_softmax(x)\n","    \n","#  you can set epoch size\n","def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","k_folds = 3\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","# set the epoch\n","epochs = 15\n","\n","\n","# loop over the dataset multiple times\n","losses = []\n","accuracies = []\n","results = {}\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(train_set)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Sample elements randomly from a given list of ids, no replacement.\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    # Define data loaders for training and testing data in this fold\n","    trainloader = torch.utils.data.DataLoader(\n","                      train_set, \n","                      batch_size=10, sampler=train_subsampler)\n","    testloader = torch.utils.data.DataLoader(\n","                      train_set,\n","                      batch_size=10, sampler=test_subsampler)\n","    model = CNN()\n","    model.apply(reset_weights)\n","    # define learning rate\n","    learning_rate = 0.005\n","    # define your optimizer with SGD and learning rate\n","    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n","    # define the loss function\n","    criterion = nn.CrossEntropyLoss()\n","    for i in range(epochs):\n","      correct = 0\n","      training_start_time = time.time()\n","      for j,(images,targets) in enumerate(train_loader):\n","        #making predictions\n","        y_pred = model(images)\n","        #calculating loss\n","        loss = criterion(y_pred,targets.reshape(-1))\n","        #backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        correct += (y_pred.argmax(axis = 1) == targets).float().sum()\n","      accuracy = 100 * correct / len(train_set)\n","      if i>10:\n","        optimizer.lr = 0.0005\n","      print(loss)\n","      print(accuracy)\n","      losses.append(loss)\n","      accuracies.append(accuracy)\n","\n","    print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n","    print(f'accuracy during training is {accuracy.item()}')\n","     # Evaluationfor this fold\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","\n","      # Iterate over the test data and generate predictions\n","      for i, data in enumerate(testloader, 0):\n","\n","        # Get inputs\n","        inputs, targets = data\n","\n","        # Generate outputs\n","        outputs = model(inputs)\n","\n","        # Set total and correct\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","      # Print accuracy\n","      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n","      print('--------------------------------')\n","      results[fold] = 100.0 * (correct / total)\n","    \n","# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","for key, value in results.items():\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","print(f'Average: {sum/len(results.items())} %')\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# losses is the list of losses generated during training\n","plt.plot([loss.detach().numpy() for loss in losses])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","plt.show()\n","# losses is the list of losses generated during training\n","plt.plot([acc.detach().numpy() for acc in accuracies])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Accuracy')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"F6eUUYkB4mBM"},"source":["### Without Batch Normalization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dj4AeMIB4mBM"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"79TKVR-_4mBM"},"source":["## L1 and L2 regularization#"]},{"cell_type":"markdown","metadata":{"id":"1bV9VYII4mBM"},"source":["### L1 Regularization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9nF-LxzQ4mBM"},"outputs":[],"source":["\n","#  you can set epoch size\n","def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","model = CNN()\n","k_folds = 5\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","# set the epoch\n","epochs = 3\n","\n","\n","# loop over the dataset multiple times\n","losses = []\n","accuracies = []\n","results = {}\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(train_set)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Sample elements randomly from a given list of ids, no replacement.\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    # Define data loaders for training and testing data in this fold\n","    trainloader = torch.utils.data.DataLoader(\n","                      train_set, \n","                      batch_size=10, sampler=train_subsampler)\n","    testloader = torch.utils.data.DataLoader(\n","                      train_set,\n","                      batch_size=10, sampler=test_subsampler)\n","    model = CNN()\n","    model.apply(reset_weights)\n","    # define learning rate\n","    learning_rate = 0.005\n","    # define your optimizer with SGD and learning rate\n","    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n","    # define the loss function\n","    criterion = nn.CrossEntropyLoss()\n","    for i in range(epochs):\n","      correct = 0\n","      training_start_time = time.time()\n","      for j,(images,targets) in enumerate(train_loader):\n","        l1_lambda = 0.001\n","        l1_reg = torch.tensor(0., requires_grad=True)\n","        for name, param in model.named_parameters():\n","            if 'weight' in name:\n","                l1_reg = l1_reg + torch.norm(param, 1)\n","        #making predictions\n","        y_pred = model(images)\n","        #calculating loss\n","        loss = criterion(y_pred,targets.reshape(-1))\n","        #backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        correct += (y_pred.argmax(axis = 1) == targets).float().sum()\n","      accuracy = 100 * correct / len(train_set)\n","      if i>10:\n","        optimizer.lr = 0.0005\n","      print(loss)\n","      print(accuracy)\n","      losses.append(loss)\n","      accuracies.append(accuracy)\n","\n","    print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n","     # Evaluationfor this fold\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","\n","      # Iterate over the test data and generate predictions\n","      for i, data in enumerate(testloader, 0):\n","\n","        # Get inputs\n","        inputs, targets = data\n","\n","        # Generate outputs\n","        outputs = model(inputs)\n","\n","        # Set total and correct\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","      # Print accuracy\n","      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n","      print('--------------------------------')\n","      results[fold] = 100.0 * (correct / total)\n","    \n","# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","for key, value in results.items():\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","print(f'Average: {sum/len(results.items())} %')\n","\n","print('Complete Training')\n","# losses is the list of losses generated during training\n","plt.plot([loss.detach().numpy() for loss in losses])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","plt.show()\n","# losses is the list of losses generated during training\n","plt.plot([acc.detach().numpy() for acc in accuracies])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Accuracy')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"XNLdfIPK4mBM"},"source":["### L2 Regularization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5b9hBPbX4mBM"},"outputs":[],"source":["\n","def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","model = CNN()\n","k_folds = 5\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","# set the epoch\n","epochs = 3\n","\n","\n","# loop over the dataset multiple times\n","losses = []\n","accuracies = []\n","results = {}\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(train_set)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Sample elements randomly from a given list of ids, no replacement.\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    # Define data loaders for training and testing data in this fold\n","    trainloader = torch.utils.data.DataLoader(\n","                      train_set, \n","                      batch_size=10, sampler=train_subsampler)\n","    testloader = torch.utils.data.DataLoader(\n","                      train_set,\n","                      batch_size=10, sampler=test_subsampler)\n","    model = CNN()\n","    model.apply(reset_weights)\n","    # define learning rate\n","    learning_rate = 0.005\n","    # define your optimizer with SGD and learning rate\n","    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n","    # define the loss function\n","    criterion = nn.CrossEntropyLoss()\n","    for i in range(epochs):\n","      correct = 0\n","      training_start_time = time.time()\n","      for j,(images,targets) in enumerate(train_loader):\n","        l2_lambda = 0.01\n","        l2_reg = torch.tensor(0., requires_grad=True)\n","        for name, param in model.named_parameters():\n","            if 'weight' in name:\n","                l2_reg = l2_reg + torch.norm(param, 2)\n","        #making predictions\n","        y_pred = model(images)\n","        #calculating loss\n","        loss = criterion(y_pred,targets.reshape(-1))\n","        #backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        correct += (y_pred.argmax(axis = 1) == targets).float().sum()\n","      accuracy = 100 * correct / len(train_set)\n","      if i>10:\n","        optimizer.lr = 0.0005\n","      print(loss)\n","      print(accuracy)\n","      losses.append(loss)\n","      accuracies.append(accuracy)\n","\n","    print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n","     # Evaluationfor this fold\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","\n","      # Iterate over the test data and generate predictions\n","      for i, data in enumerate(testloader, 0):\n","\n","        # Get inputs\n","        inputs, targets = data\n","\n","        # Generate outputs\n","        outputs = model(inputs)\n","\n","        # Set total and correct\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","      # Print accuracy\n","      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n","      print('--------------------------------')\n","      results[fold] = 100.0 * (correct / total)\n","    \n","# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","for key, value in results.items():\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","print(f'Average: {sum/len(results.items())} %')\n","\n","\n","print('Complete Training')\n","# losses is the list of losses generated during training\n","plt.plot([loss.detach().numpy() for loss in losses])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","plt.show()\n","# losses is the list of losses generated during training\n","plt.plot([acc.detach().numpy() for acc in accuracies])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Accuracy')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"9ZmMdHcU4mBM"},"source":["## Dropout"]},{"cell_type":"markdown","metadata":{"id":"B5KDqGNI4mBM"},"source":["### With Dropout"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0-kHpSeF4mBM"},"outputs":[],"source":["# define the model\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(1,10,5)    # Convolutional layer\n","        self.conv2 = nn.Conv2d(10,20,3)\n","\n","        self.fc1 = nn.Linear(20*10*10,500)\n","        self.fc2 = nn.Linear(500, 47)\n","\n","        self.dropout = nn.Dropout(p=0.5)\n","\n","    def forward(self, x):     \n","        input_size = x.size(0)\n","        # in: batch*1*28*28, out: batch*10*24*24(28-5+1)\n","        x = self.conv1(x)\n","        # out: batch*10*24*24\n","        x = F.relu(x)\n","        # in: batch*10*24*24, out: batch*10*12*12\n","        x = F.max_pool2d(x,2,2)\n","\n","        # in: batch*10*12*12, out: batch*20*10*10 (12-3+1)\n","        x = self.conv2(x)\n","        x = F.relu(x)\n","\n","        # 20*10*10 = 2000\n","        x = x.view(input_size,-1)\n","\n","        # in: batch*2000  out:batch*500\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","\n","        # in:batch*500 out:batch*10\n","        x = self.fc2(x)\n","        return F.log_softmax(x)\n","    \n","#  you can set epoch size\n","def reset_weights(m):\n","  '''\n","    Try resetting model weights to avoid\n","    weight leakage.\n","  '''\n","  for layer in m.children():\n","   if hasattr(layer, 'reset_parameters'):\n","    print(f'Reset trainable parameters of layer = {layer}')\n","    layer.reset_parameters()\n","model - CNN()\n","k_folds = 3\n","kfold = KFold(n_splits=k_folds, shuffle=True)\n","# set the epoch\n","epochs = 15\n","\n","\n","# loop over the dataset multiple times\n","losses = []\n","accuracies = []\n","results = {}\n","for fold, (train_ids, test_ids) in enumerate(kfold.split(train_set)):\n","    \n","    # Print\n","    print(f'FOLD {fold}')\n","    print('--------------------------------')\n","    \n","    # Sample elements randomly from a given list of ids, no replacement.\n","    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n","    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n","    \n","    # Define data loaders for training and testing data in this fold\n","    trainloader = torch.utils.data.DataLoader(\n","                      train_set, \n","                      batch_size=10, sampler=train_subsampler)\n","    testloader = torch.utils.data.DataLoader(\n","                      train_set,\n","                      batch_size=10, sampler=test_subsampler)\n","    model = CNN()\n","    model.apply(reset_weights)\n","    # define learning rate\n","    learning_rate = 0.005\n","    # define your optimizer with SGD and learning rate\n","    optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n","    # define the loss function\n","    criterion = nn.CrossEntropyLoss()\n","    for i in range(epochs):\n","      correct = 0\n","      training_start_time = time.time()\n","      for j,(images,targets) in enumerate(train_loader):\n","        #making predictions\n","        y_pred = model(images)\n","        #calculating loss\n","        loss = criterion(y_pred,targets.reshape(-1))\n","        #backprop\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        correct += (y_pred.argmax(axis = 1) == targets).float().sum()\n","      accuracy = 100 * correct / len(train_set)\n","      if i>10:\n","        optimizer.lr = 0.0005\n","      print(loss)\n","      print(accuracy)\n","      losses.append(loss)\n","      accuracies.append(accuracy)\n","\n","    print('Training finished, took {:.2f}s'.format(time.time() - training_start_time))\n","    print(f'accuracy during training is {accuracy.item()}')\n","     # Evaluationfor this fold\n","    correct, total = 0, 0\n","    with torch.no_grad():\n","\n","      # Iterate over the test data and generate predictions\n","      for i, data in enumerate(testloader, 0):\n","\n","        # Get inputs\n","        inputs, targets = data\n","\n","        # Generate outputs\n","        outputs = model(inputs)\n","\n","        # Set total and correct\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += targets.size(0)\n","        correct += (predicted == targets).sum().item()\n","\n","      # Print accuracy\n","      print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n","      print('--------------------------------')\n","      results[fold] = 100.0 * (correct / total)\n","    \n","# Print fold results\n","print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n","print('--------------------------------')\n","sum = 0.0\n","for key, value in results.items():\n","  print(f'Fold {key}: {value} %')\n","  sum += value\n","print(f'Average: {sum/len(results.items())} %')\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# losses is the list of losses generated during training\n","plt.plot([loss.detach().numpy() for loss in losses])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Training Loss')\n","plt.show()\n","# losses is the list of losses generated during training\n","plt.plot([acc.detach().numpy() for acc in accuracies])\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.title('Accuracy')\n","plt.show()"]},{"cell_type":"code","source":[],"metadata":{"id":"VMuZKGxhbB56"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"toc_visible":true,"provenance":[],"mount_file_id":"1144sUazzNKl1yvs592U5WterwQcqorKO","authorship_tag":"ABX9TyOGm3CH70Vg1BwmKKwdOoIF"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}